CONTENT

Section 2 9. Recap - Kubernetes Architecture
Section 2 10. Docker vs ContainerD
Section 2 11. Recap - PODS
Section 2 12. YAML Basics
Section 2 13. Recap - Pods with YAML
Section 2 14. Recap - Demo - Creating Pods with YAML
Section 2 15. Note!
Section 2 20. Practice Test - Pods
Section 2 21. Edit Pods
Section 2 22. Recap - ReplicaSets
Section 2 24. Practice Test - ReplicaSets
Section 2 25. Recap - Deployments
Section 2 27. Practice Test - Deployments
Section 2 28. Certification Tip: Formatting Output with kubectl
Section 2 29. Recap - Namepsaces
Section 2 31. Practice Test - Namespaces
Section 2 32. Certification Tip: Imperative Commands
Section 2 34. Practice Test - Imperative Commands





============================================
Section 2 9. Recap - Kubernetes Architecture
============================================

NODE - Phisical or Virtual machine on which kubernetes is installed. A node is a worker machine where containers are lounched by kubernetes. Nodes were called minions in the past.

CLUSTER is a set of nodes that work together. In this case if one node stop, the application is still available on the other nodes. Also load is shared between nodes.

MASTER NODE - watches over the worker nodes. Master node is resonsible for container orchestration on the worker nodes.

When we install kubernetes on a platform we install the components as follow
	1. API Server
	2. ETCD Server
	3. Scheduler
	4. Controllers
	5. Container Runtime
	6. kubelet

1. The API Server - act like frontend for kubernetes. Users, management devices, command line interfaces etc. all talk to the API Server to interact with the kubernetes cluster.

2. ETCD key-value store - distributed reliable key-value store used by kubernetes to store all data used to manage the cluster. When we have multiple nodes and multiple masters oin the cluster, ETCD stores all that information on all the nodes in the cluster in a distributed manner. ETCD is responsible for implementing logs within the cluster to ensure that there is no conflicts between the masters.

3. The Scheduler is responsoble for distributing work or containers across multiple nodes. It looks for newly created containers and assign them to nodes.

4. The Controllers are the brain behind orchestration. They are responsible for noticing and responding when nodes, containers or endpoints goes down. The controllers makes desitions to bring up new containers in such cases.

5. The container runtime is the underline software that is used to run containers. In our case it happens to be Docker. There are alternatives such as RKT (rocket) or CRI-O

6. Kubelet is the agent that runs on each node on the cluster. The agent is responsible for making sure that the containers are running on the nodes as expected.



Master Nodes vs. Worker Nodes
-----------------------------

On master node we have installed KUBE-APISERVER
On worker nodes we have KUBELET and Container Runtime (Docker)

The kubelet agent on the woker nodes are responsible for interacting with the api-server on the master node to provide help information of the worker node and carry out actions requested by the master on the worker nodes.

All information gathered is stored on the key-value store on the master (ETCD framework - DB server)

The Master also have the controller manager and the scheculler.


Kubectl - command line utilities
-------

The kubectl tool is used to deploy and manage applications on kubernetes cluster. To get cluster information, to get status of other nodes in the cluster and manage many other things.


Some common commands:
---------------------

Deploy application on the cluster
	terminal --> kubectl run

Show details for the cluster
	terminal --> kubectl cluster-info

List all nodes part of the cluster
	terminal --> kubectl get nodes




==================================
Section 2 10. Docker vs ContainerD
==================================

OCI - open container initiative requirements
	- imagespec			- how an image should be build
	- runtimespec			- how container runtime should be developed

CRI - container runtime interface 

ContainerD is the container runtime interface of Docker, but it can be used separatelly.

ContainerD comes with few utility tools (CLIs) - ctr, nerdcli, crictl

ctr - comes from container_d, but have limited features. Not very user friendly, used mostly for debugging
===

examples
-------------------------------------------------------------------------------
terminal --> ctr images pull docker.io/library/redis:alpine	# pull image
terminal --> ctr run docker.io/library/redis:alpine redis	# run container
-------------------------------------------------------------------------------



nerdcli 
======= 
	- docker like cli for container_d
	- support docker compose
	- support newest features of container_d
		- Enrypted container images
		- P2P image distribution
		- Image signing and verifying
		- Namespaces in Kubernetes
examples
-------------------------------------------------------------------------------
terminal --> nerdctl run --name redis redis:alpine		# run container
terminal --> nerdctl run --name webserver -p 80:80 -d nginx 	# run webserver with ports
-------------------------------------------------------------------------------



crictl
======	- cli for CRI (Container Runtime Interface - directly with Kubernetes, support all other CRIs)
	- installed separatelly
	- Used to inspect and debug container runtime
		- not to create containers
	- works across different runtimes
	- in conflic with kubelet - if we create container with crictl, kubelet will destroy it
	- used mostrly for developing, debugging and container inspecting

examples
-------------------------------------------------------------------------------
terminal --> crictl pull busybox				# pull image
terminal --> crictl images					# list images
terminal --> crictl ps -a 					# list all containers
terminal --> crictl exec -it 0w34e34545232e33345d44533 ls	# execute command in specific container
terminal --> crictl logs 0w34e34545232				# show logs of specific conatiner	
terminal --> crictl pods					# show pods !!! Aware of pods
-------------------------------------------------------------------------------


		CTR			NERDCTL				CRICTL
---------------------------------------------------------------------------------
Pyrpose		Debugging		General Purpose			Debugging
---------------------------------------------------------------------------------
Community	ContainerD		ContainerD			Kubernetes
Works With	ContainerD		ContainerD			All CRI Compatible Runtimes



==========================
Section 2 11. Recap - PODS
==========================

Assumptions
	- ready to deploy application image, available in docker registry
	- set up and working kubernetes cluster
	- all services must be in a running state

POD - sigle instance of an application. The smallest object in kubenetes system

POD can have multiple containers but not of the same kind (2 same containers)
	- these containers share pod network and storage - internal 'localhost' and volume 
		- app-container
		- helper-contaier (additional service in one-to-one relationship with app-contaier)

In POD can be created app-contaier and helper-container with all common components (spacename, storage, network, etc)


Common commands
===============

create POD with nginx
---------------------
	terminal --> kubectl run nginx --image nginx

list pods in the cluster
------------------------
	terminal --> kubectl get pods



=========================
Section 2 12. YAML Basics
=========================

Going forward we will be working with YAML files to create and configure Kubernetes Objects. If you are new to YAML, please refer to the YAML basics and exercises in the "Kubernetes for the Absolute Beginners course". In the next lecture we will discuss how to configure a YAML file for PODs.



====================================
Section 2 13. Recap - Pods with YAML
====================================

pod-definition.yml
------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
      app: myapp
      type: front-end
spec:
  containers:		
    - name: nginx-container	
      image: nginx		
------------------------------------------


apiVersion - kubenetes api version
----------

- Possible values

	Kind		Version
	-----------------------
	POD		v1
	Service		v1
	Replica		apps/v1
	Deployment	apps/v1


kind - type of object we are trying to create
----

- Possible values

	Kind		Version
	-----------------------
	POD		v1
	Service		v1
	Replica		apps/v1
	Deployment	apps/v1



metadata - data about the object, dictionary format
--------

example
--------------------
metadata:
  name: myapp-pod	# name of the pod
  labels:
      app: myapp	# name of the app
      type: front-end	# type is used to filter containers
--------------------

# under 'metadata' we can have only expected by kubernetes properties
# unde 'labels' we can set key-value pair of our choice


spec - dictionary format for container configuration
----

example
--------------------
spec:
  containers:			# List/Array
    - name: nginx-container	# set container name
      image: nginx		# set image for the container
--------------------


Commands
========

Create POD command
------------------
	terminal --> kubectl create -f pod-definition.yml

List pods
---------
	terminal --> kubectl get pods

Show info for specific pod
--------------------------
	terminal --> kubectl describe pod myapp-pod




====================================================
Section 2 14. Recap - Demo - Creating Pods with YAML
====================================================

We will use PyCharm free Python editor, because it have a good yaml support addons. Download Pycharm Community (free) version
Download and install PyCharm Community Edition - https://www.jetbrains.com/pycharm/download/?section=windows

Install the 'YAML' plugin by JetBrains if not installed - https://plugins.jetbrains.com/plugin/13126-yaml
	- Settings/plugins/YAML/install

Enable file structure view
	View/Tool Windows/Structure (Alt + F7)


Create new project in folder by choice.

Create new file
	- right mouse click/new/file
	- name the file 'pod-definition.yml'


pod-definition.yml
------------------------------------------
apiVersion: v1

kind: Pod

metadata:
  name: myapp-pod
  labels:
      app: myapp-pod

spec:
  containers:
    - name: nginx
      image: nginx	
------------------------------------------

We can see the structure window details for the different sections. PyCharm check automatically the YAML formactting for us.


We can now create the pod with the created file in Kubernetes.

Go to the master node and craete folder structure
	terminal --> mkdir demos
	terminal --> mkdir demos/pod


Create pod-definition file in the created directory
Enter the created folder
	terminal --> cd demos/pod

Create pod-definition.yaml file
	terminal --> cat > pod-definition.yaml

Paste the file structure from PyCharm

pod-definition.yml
------------------------------------------
apiVersion: v1

kind: Pod

metadata:
  name: myapp-pod
  labels:
      app: myapp-pod

spec:
  containers:
    - name: nginx
      image: nginx	
------------------------------------------

Verify the content of the file
	terminal --> cat pod-definition.yml

Create the pod
	terminal --> kubectl create -f pod-definition.yml

Wait few minutes for pod to be created

Verify pod creation
	terminal --> kubectl get pods



===================
Section 2 15. Note!
===================

The previous lecture was for informational purposes only. In the real exam, you will not be able to use PyCharm. You will need to use an editor available in Linux such as vi or nano. When working on labs, practice working with one of these editors. We demo how to work with vi editor in the solution videos of the labs.


==========================================
Section 2 16. Practice Test - Introduction
==========================================

Info for practice environments on KodeKloud.


===================================
Section 2 17. Demo - Accessing Labs
===================================

Instructions for accessing the practice environments on KodeKloud.


===============================================
Section 2 18. Course Setup - Accessing the Labs
===============================================

Info for practice environments on KodeKloud.


==================================
Section 2 20. Practice Test - Pods
==================================

Set environment alias and autocomletion
Info - https://kubernetes.io/pt-br/docs/reference/kubectl/cheatsheet/

Set alias
	terminal --> alias k=kubectl
	terminal --> complete -o default -F __start_kubectl k

Set autocompletion
	terminal --> source <(kubectl completion bash) # configuração de autocomplete no bash do shell atual, o pacote bash-completion precisa ter sido instalado primeiro.
	terminal --> echo "source <(kubectl completion bash)" >> ~/.bashrc # para adicionar o autocomplete permanentemente no seu shell bash.

We can check if autocompletion is set
	terminal --> kubectl get + (double tab)
	
	# if settings appear, then the automcompletion is set




1. How many pods exist on the system?
-------------------------------------
In the current(default) namespace.


List pods in the current namespace
	terminal --> k get pods

	# result: No resources found in default namespace.

- choose '0' as answer






2. Create a new pod with the nginx image.
-----------------------------------------

Show help commands for creating a pod
	terminal --> kubectl run --help

We can use the first example
  # Start a nginx pod
  kubectl run nginx --image=nginx

Create the pod 
	terminal --> k run nginx --image=nginx

	# k			- common kubernetes command
	# run 			- start a pod
	# nginx			- name of the pod
	# --image=nginx		- used image

	# result: pod/nginx created





3. How many pods are created now?
---------------------------------
Note: We have created a few more pods. So please check again in the current(default) namespace.

List pods in current namespace
	terminal --> k get pods


# result:
--------------------------------------------------
NAME            READY   STATUS    RESTARTS   AGE
newpods-2n8kb   1/1     Running   0          4m53s
newpods-fzg8g   1/1     Running   0          4m53s
newpods-ls94c   1/1     Running   0          4m53s
nginx           1/1     Running   0          45s
--------------------------------------------------

Print the count of the pods in the current namespace
	terminal --> k get pods --no-headers | wc -l

	# result: 4


- choose '4' as answer






4. What is the image used to create the new pods?
-------------------------------------------------
You must look at one of the new pods in detail to figure this out.

List pods in current namespace
	terminal --> k get pods


# result:
--------------------------------------------------
NAME            READY   STATUS    RESTARTS   AGE
newpods-2n8kb   1/1     Running   0          4m53s
newpods-fzg8g   1/1     Running   0          4m53s
newpods-ls94c   1/1     Running   0          4m53s
nginx           1/1     Running   0          45s
--------------------------------------------------


Show details for one of the pods except 'nginx' pod
	terminal --> k describe pod newpods-ls94c

	# search for 'Image' field in the result

# result:
Containers:
  busybox:
    Container ID:  containerd://7c1d67d2f7b27b0e9b3cab0321ed0a05cfb59516d3a7930e1265a999c9352981
    Image:         busybox		# this is the image
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0

Or print the 'Image' section found in the description
	terminal --> terminal --> k describe pod newpods-ls94c | grep Image

# result:
-----------------------------------------------------------------
    Image:         busybox		# this is the image
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0
  Normal  Pulled     10m   kubelet            Successfully pulled image "busybox" in 355ms (355ms including waiting). Image size: 2167176 bytes.
-----------------------------------------------------------------

- choose 'BUSYBOX' as asnwer





5. Which nodes are these pods placed on?
----------------------------------------
You must look at all the pods in detail to figure this out.

List nodes
	terminal --> k get nodes

	# result:
	NAME           STATUS   ROLES                  AGE   VERSION
	controlplane   Ready    control-plane,master   21m   v1.32.0+k3s1	# the only node is the controlplane

List pods with additional information
	terminal --> k get pods -o wide

	# k			- common kubernetes command
	# get 			- action
	# pods			- objects
	# -o			- output
	# wide			- print additional information
	

# result:
----------------------------------------------------------
NAME            READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
newpods-2n8kb   1/1     Running   0          16m   10.22.0.9    controlplane   <none>           <none>
newpods-fzg8g   1/1     Running   0          16m   10.22.0.11   controlplane   <none>           <none>
newpods-ls94c   1/1     Running   0          16m   10.22.0.10   controlplane   <none>           <none>
nginx           1/1     Running   0          11m   10.22.0.12   controlplane   <none>           <none>
----------------------------------------------------------	
								# this column

We can see that there is and column 'NODE' that we can see what node is every pod deployed on

- choose 'controlplane' as asnwer






6. How many containers are part of the pod webapp?
--------------------------------------------------
Note: We just created a new POD. Ignore the state of the POD for now.

List pods
	etrminal --> k get pods

# result:
--------------------------------------------------------------
NAME            READY   STATUS             RESTARTS        AGE
newpods-2n8kb   1/1     Running            1 (2m58s ago)   19m
newpods-fzg8g   1/1     Running            1 (2m58s ago)   19m
newpods-ls94c   1/1     Running            1 (2m58s ago)   19m
nginx           1/1     Running            0               15m
webapp          1/2     ImagePullBackOff   0               2m19s		# web app pods
--------------------------------------------------------------

We can see the webapp have '1/2' in READY column. This mean that the pod are 2 in total.


Or show detailed information for pod 'webapp'
	terminal --> k describe pod webapp

	# under 'Containers' section we have 2 entities

	# result:
------------------------------------
...
Containers:
  nginx:												# first entity 
    Container ID:   containerd://e3b6d2f3252fbcf8a5752fa29f1c89eea6c3692fe6684f7096e13a6c700fc787
    Image:          nginx
...
  agentx:												# second entity
    Container ID:   
    Image:          agentx
...
------------------------------------

- choose '2' as answe






7. What images are used in the new webapp pod?
----------------------------------------------
You must look at all the pods in detail to figure this out.

Or show detailed information for pod 'webapp'
	terminal --> k describe pod webapp

	# under 'Containers' section we have 2 entities and used images

	# result:
------------------------------------
...
Containers:
  nginx:												# first entity 
    Container ID:   containerd://e3b6d2f3252fbcf8a5752fa29f1c89eea6c3692fe6684f7096e13a6c700fc787
    Image:          nginx										# used image
...
  agentx:												# second entity
    Container ID:   
    Image:          agentx										# used image
...
------------------------------------

Or print 'Images' sections from the describtion of the pods
	terminal --> terminal --> k describe pod webapp | grep Image

# result:
-----------------------------------------------------------------
    Image:          nginx						# first used image
    Image ID:       docker.io/library/nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496
    Image:          agentx						# second used image
    Image ID:  
...
-----------------------------------------------------------------

- choose 'nginx & agentx' as answer






8. What is the state of the container agentx in the pod webapp?
---------------------------------------------------------------
Wait for it to finish the ContainerCreating state


Print description of pod 'webapp'
	terminal --> k describe pod webapp

Under 'Containers' section we can see details for every container in the pod

-----------------------------------------------------------
...
Containers:
  nginx:
    Container ID:   containerd://e3b6d2f3252fbcf8a5752fa29f1c89eea6c3692fe6684f7096e13a6c700fc787
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496
    Port:           <none>
    Host Port:      <none>
    State:          Running					# state for the first container
      Started:      Thu, 27 Feb 2025 11:55:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-m9gmf (ro)
  agentx:
    Container ID:   
    Image:          agentx
    Image ID:       
    Port:           <none>
    Host Port:      <none>
    State:          Waiting					# state for the second container
      Reason:       ImagePullBackOff
    Ready:          False
...
-----------------------------------------------------------

- choose 'Error or Waiting' as answer






9. Why do you think the container agentx in pod webapp is in error?
-------------------------------------------------------------------
Try to figure it out from the events section of the pod.


Print description of pod 'webapp'
	terminal --> k describe pod webapp


In the result we can see 'Events' section in the end of the description

# result:
----------------------------------------------------------------
...
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  12m                  default-scheduler  Successfully assigned default/webapp to controlplane
  Normal   Pulling    12m                  kubelet            Pulling image "nginx"
  Normal   Pulled     12m                  kubelet            Successfully pulled image "nginx" in 169ms (170ms including waiting). Image size: 72195292 bytes.
  Normal   Created    12m                  kubelet            Created container: nginx
  Normal   Started    12m                  kubelet            Started container nginx
  Normal   Pulling    9m13s (x5 over 12m)  kubelet            Pulling image "agentx"
  Warning  Failed     9m13s (x5 over 12m)  kubelet            Failed to pull image "agentx": failed to pull and unpack image "docker.io/library/agentx:latest": failed to resolve reference "docker.io/library/agentx:latest": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Warning  Failed     9m13s (x5 over 12m)  kubelet            Error: ErrImagePull
  Normal   BackOff    118s (x44 over 12m)  kubelet            Back-off pulling image "agentx"
  Warning  Failed     118s (x44 over 12m)  kubelet            Error: ImagePullBackOff
...
----------------------------------------------------------------

We can see the error message in the events.

- choose 'A Docker image with this image do not exist on Docker Hub' as asnwer
 






10. What does the READY column in the output of the kubectl get pods command indicate?
--------------------------------------------------------------------------------------

- choose 'Running Containers in POD/Total Containers in POD' as answer





11. Delete the webapp Pod.
--------------------------
Once deleted, wait for the pod to fully terminate.


List pods
	terminal --> k get pods

# result:
--------------------------
NAME            READY   STATUS             RESTARTS        AGE
newpods-2n8kb   1/1     Running            2 (4m33s ago)   37m
newpods-fzg8g   1/1     Running            2 (4m33s ago)   37m
newpods-ls94c   1/1     Running            2 (4m33s ago)   37m
nginx           1/1     Running            0               33m
webapp          1/2     ImagePullBackOff   0               20m
--------------------------

Delete the webapp pod
	terminal --> k delete pod webapp
	
	# result: pod "webapp" deleted


- click 'Check' button




12. Create a new pod with the name redis and the image redis123.
----------------------------------------------------------------
Use a pod-definition YAML file. And yes the image name is wrong!


Print pod definition file
	terminal --> k run redis --image=redis123 --dry-run=client -o yaml

# result:
--------------------------------
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: redis
  name: redis
spec:
  containers:
  - image: redis123
    name: redis
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
--------------------------------


Create pod definition file 'pod1' and DO NOT create the pod
	terminal --> k run redis --image=redis123 --dry-run=client -o yaml > pod1.yaml

	# k			- common kubernetes command
	# run 			- start pod
	# redis			- pod name
	# --image=redis123	- used image
	# --dry-run=client	- do not start the pod
	# -o yaml		- set output in yaml format
	# > pod1.yaml		- save the result in the pod1.yaml file


Verify the file creation
	terminal --> cat pod1.yaml

Create the pod using the created pod definition file pod1.yaml
	terminal --> k create -f pod1.yaml

	# result: pod/redis created

Verify pod creation
	terminal --> k get pods





13. Now change the image on this pod to redis.
----------------------------------------------
Once done, the pod should be in a running state.

We can edit the pod or edit the pod definition file, change the image and apply changes

Edit the pod definition file pod1.yaml with vim
	terminal --> vi pod1.yaml

# result:
-------------------------------
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: redis
  name: redis
spec:
  containers:
  - image: redis		# changed from 'redis123' to 'redis' 
    name: redis
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
-------------------------------
Save changes - escape, :wq!, enter


Apply the canges
	terminal --> k apply -f pod1.yaml

# result:
-------------------------------
Warning: resource pods/redis is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
pod/redis configured
-------------------------------


Verify pod modification
	terminal --> k get pods

# result:
-------------------------------------------------------
NAME            READY   STATUS    RESTARTS        AGE
newpods-2n8kb   1/1     Running   3 (3m10s ago)   53m
newpods-fzg8g   1/1     Running   3 (3m10s ago)   53m
newpods-ls94c   1/1     Running   3 (3m10s ago)   53m
nginx           1/1     Running   0               49m
redis           1/1     Running   0               9m16s		# the pod is running now
-------------------------------------------------------

- click 'Check' button




=======================
Section 2 21. Edit Pods
=======================

A Note on Editing Existing Pods
In any of the practical quizzes, if you are asked to edit an existing POD, please note the following:

If you are given a pod definition file, edit that file and use it to create a new pod.

If you are not given a pod definition file, you may extract the definition to a file using the below command:
	terminal --> kubectl get pod <pod-name> -o yaml > pod-definition.yaml

Then edit the file to make the necessary changes, delete, and re-create the pod.

To modify the properties of the pod, you can utilize the 'kubectl edit pod <pod-name>' command. Please note that only the properties listed below are editable.

spec.containers[*].image
spec.initContainers[*].image
spec.activeDeadlineSeconds
spec.tolerations
spec.terminationGracePeriodSeconds





=================================
Section 2 22. Recap - ReplicaSets
=================================

Kubernetes Controllers - Monitoring Kubernetes Objects and respond accordingly

Replication Controllers / ReplicaSet
------------------------------------
- Providing High Availability in Kubernetes cluster as running multiple instances or replace single instance on failure in a Node.
- Load Balancing & Scaling as start additional PODs if demand increases. Can start PODs on different Nodes in the cluster when current one have no more resources.

Replication Controller is used in the past. More likely is to use ReplicaSets in real project.


CREATE REPLICATION CONTROLLER
=============================

rc-definition.yml
-----------------------------------
apiVersion: v1
kind: ReplicationController
metadata:
  name: myapp-rc
  labels:
    app: myapp
    type: front-end

spec:
  template:			# definition of the POD we use the template for
    metadata:
      name: myapp-pod
      labels:
        app: myapp-pod
        tier: front-end
    spec:
      containers:		
      - name: nginx-container
        image: nginx

  replicas: 3			# set pod count
-----------------------------------    


Create replication controller
-----------------------------
	terminal --> kubectl create -f rc-definition.yml

	# replicationcontroller "myapp-rc" created


List Replication Controllers
----------------------------
	terminal --> kubectl get replicationcontroller

List PODs
---------
	terminal --> kubectl get pods

	# name of the pods starting with 'myapp-rc-xxxxx', cuz they are created by replication controller




CREATE REPLICA SET
==================

replicaset-definition.yml
-----------------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-replicaset
  labels:
    app: myapp
    type: front-end

spec:
  template:			# definition of the POD is needed if replacing failed POD
    metadata:
      name: myapp-pod
      labels:
        app: myapp
        tier: frontend
    spec:
      containers:		
      - name: nginx-container
        image: nginx

  replicas: 3			# set pod count
  selector: 			# selector is used to consider PODs created not by replication controller only
    matchLabels:		# set label for othe PODs from the specific type
      type: front-end
-----------------------------------  

The difference between Replication Controller and Replicaset is that the selector section in Replicaset is required. Replicasets will manage pods that are not part of the Replicaset creation. Replicaset will take consideration of types specified in the 'selector/matchLabesl' section and manage the pods.


TroubleShooting
---------------
If we mistake 'apiVersion: v1' - apiVersion for Replication Controller, we will get this error:
'error: unable to recognize "replicaset-definition.yml": no matches for /, Kind=ReplicaSet'


Create ReplicaSet
=================
	terminal --> kubectl create -f replicaset-definition.yml

	# replicaset "myapp-replicaset" created

List replicasets
----------------
	terminal --> kubectl get replicaset

List PODs
---------
	terminal --> kubectl get pods


Labels and Selectors
====================

We create a replicaset that maintain 3 replicas of our application. The Replicaset will monitor each pod and deploy new one if any one of them fails. The pods the Replicaset monitor is sepcified by the 'selector/matchLabels' section in the replicaset definition file.


SCALE NUMBER OF PODS
====================

Option 1:
	- update '  replicas: 6' in the replicaset definition file
	- refresh replicaset-definition.yml file
	terminal --> kubectl replace -f replicaset-definition.yml

	# kubectl 			- common kubernetes commnad
	# replace			- used action
	# -f replicaset-definition.yml	- specify the file

Option 2:
	- one line commnad using definition file
	terminal --> kubectl scale --replicas=6 -f replicaset-definition.yml

	# kubectl 			- common kubernetes commnad
	# scale				- used action
	# --replicas=6			- specify property change and value
	# -f replicaset-definition.yml	- specify the file

	- one line command using replicaset name
	terminal --> kubectl scale --replicas=6 replicaset myapp-replicaset
	
	# kubectl 			- common kubernetes commnad
	# scale				- used action
	# --replicas=6			- specify property change and value
	# replicaset			- specify type object
	# myapp-replicaset		- name of the object

	Option 2 will not change the replicas in the definition file!

ReplicaSet Commands
===================

Create ReplicaSet
-----------------
	terminal --> kubectl create -f replicaset-definition.yml

	# kubectl 			- common kubernetes commnad
	# create			- used action
	# -f replicaset-definition.yml	- specify definition file


List ReplicaSets
----------------
	terminal --> kubectl get replicaset

	# kubectl 			- common kubernetes commnad
	# get				- used action
	# replicaset			- object type


Delete ReplicaSet
-----------------
	terminal --> lubectl delete replicaset myapp-replicaset

	# kubectl 			- common kubernetes commnad
	# delete			- used action
	# replicaset			- object type
	# myapp-replicaset		- name of the object

	hint: Deletes all underlying PODs


Replace / Refresh ReplicaSet
----------------------------
	terminal --> lubectl replace -f replicaset-definition.yml

	# kubectl 			- common kubernetes commnad
	# delete			- used action
	# -f replicaset-definition.yml	- sepcify used file


Scale ReplicaSet
----------------
	- one line commnad using definition file
	terminal --> kubectl scale --replicas=6 -f replicaset-definition.yml

	# kubectl 			- common kubernetes commnad
	# scale				- used action
	# --replicas=6			- specify property change and value
	# -f replicaset-definition.yml	- specify the file

	- one line command using replicaset name
	terminal --> kubectl scale --replicas=6 replicaset myapp-replicaset
	
	# kubectl 			- common kubernetes commnad
	# scale				- used action
	# --replicas=6			- specify property change and value
	# replicaset			- specify type object
	# myapp-replicaset		- name of the object









=========================================
Section 2 24. Practice Test - ReplicaSets
=========================================

Set environment alias and autocomletion
Info - https://kubernetes.io/pt-br/docs/reference/kubectl/cheatsheet/

Set alias
	terminal --> alias k=kubectl
	terminal --> complete -o default -F __start_kubectl k

Set autocompletion
	terminal --> source <(kubectl completion bash) # configuração de autocomplete no bash do shell atual, o pacote bash-completion precisa ter sido instalado primeiro.
	terminal --> echo "source <(kubectl completion bash)" >> ~/.bashrc # para adicionar o autocomplete permanentemente no seu shell bash.

We can check if autocompletion is set
	terminal --> kubectl get + (double tab)
	
	# if settings appear, then the automcompletion is set





1. How many PODs exist on the system?
-------------------------------------
In the current(default) namespace.

List pods in current namespace
	terminal --> k get pods

Print the count of tpods in current namespace
	terminal --> k get pods --no-headers | wc -l


- choose '0' as answer




2. How many ReplicaSets exist on the system?
--------------------------------------------
In the current(default) namespace.

List replicasets in the current namespace
	terminal --> k get replicaset 

Print the count of replicasets in current namespace
	terminal --> k get replicaset --no-headers | wc -l		# we can use rs for short of replicaset

- choose '0' as answer




3. How about now? How many ReplicaSets do you see?
--------------------------------------------------
We just made a few changes!


List replicasets in the current namespace
	terminal --> k get rs

Print the count of replicasets in current namespace
	terminal --> k get rs --no-headers | wc -l		

- choose '1' as answer





4. How many PODs are DESIRED in the new-replica-set?
----------------------------------------------------

List replicasets
	terminal --> k get rs

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   4         4         0       3m1s


Show details for 'new-replica-set' replicaset
	terminal --> k describe rs new-replica-set

# result:
----------------------------------
...
Replicas:     4 current / 4 desired
...
----------------------------------

- choose '4' as answer





5. What is the image used to create the pods in the new-replica-set?
--------------------------------------------------------------------

List replicasets
	terminal --> k get rs

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   4         4         0       3m1s


Show details for 'new-replica-set' replicaset
	terminal --> k describe rs new-replica-set

# result:
----------------------------------
...
    Image:      busybox777
...
----------------------------------

- choose 'busybox777' as answer





6. How many PODs are READY in the new-replica-set?
--------------------------------------------------

List replicasets
	terminal --> k get rs

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   4         4         0       3m1s


Show details for 'new-replica-set' replicaset
	terminal --> k describe rs new-replica-set

# result:
----------------------------------
...
Pods Status:  0 Running / 4 Waiting / 0 Succeeded / 0 Failed
...
----------------------------------

- choose '0' as answer




7. Why do you think the PODs are not ready?
-------------------------------------------

List pods
	etrminal --> k get pods

# result:
-----------------------------
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-49lsc   0/1     ImagePullBackOff   0          7m59s
new-replica-set-fn6gw   0/1     ImagePullBackOff   0          7m59s
new-replica-set-gnkj7   0/1     ImagePullBackOff   0          7m59s
new-replica-set-r6nnc   0/1     ImagePullBackOff   0          7m59s
-----------------------------

Show details for one of the pods
	terminal --> k describe pod new-replica-set-r6nnc


# result:
----------------------------------------------------
...
Events:
  Type     Reason     Age                     From               Message
  ----     ------     ----                    ----               -------
  Normal   Scheduled  8m34s                   default-scheduler  Successfully assigned default/new-replica-set-r6nnc to controlplane
  Normal   Pulling    5m37s (x5 over 8m34s)   kubelet            Pulling image "busybox777"
  Warning  Failed     5m36s (x5 over 8m34s)   kubelet            Failed to pull image "busybox777": failed to pull and unpack image "docker.io/library/busybox777:latest": failed to resolve reference "docker.io/library/busybox777:latest": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Warning  Failed     5m36s (x5 over 8m34s)   kubelet            Error: ErrImagePull
  Normal   BackOff    3m26s (x21 over 8m33s)  kubelet            Back-off pulling image "busybox777"
  Warning  Failed     3m26s (x21 over 8m33s)  kubelet            Error: ImagePullBackOff
----------------------------------------------------

In the 'Events' section we can see error messages

- choose 'The image BUSYBOX777 doesn't exist' as answer





8. Delete any one of the 4 PODs.
--------------------------------

List pods
	etrminal --> k get pods

# result:
-----------------------------
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-49lsc   0/1     ImagePullBackOff   0          7m59s
new-replica-set-fn6gw   0/1     ImagePullBackOff   0          7m59s
new-replica-set-gnkj7   0/1     ImagePullBackOff   0          7m59s
new-replica-set-r6nnc   0/1     ImagePullBackOff   0          7m59s
-----------------------------

Delete pod
	terminal --> k delete pod new-replica-set-r6nnc

	# result: pod "new-replica-set-r6nnc" deleted

- click 'Check' button




9. How many PODs exist now?
---------------------------

List pods
	etrminal --> k get pods

# result:
-----------------------------
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-49lsc   0/1     ImagePullBackOff   0          11m
new-replica-set-fn6gw   0/1     ImagePullBackOff   0          11m
new-replica-set-gnkj7   0/1     ImagePullBackOff   0          11m
new-replica-set-jhqh2   0/1     ErrImagePull       0          40s
-----------------------------

- choose '4' as answer





10. Why are there still 4 PODs, even after you deleted one?
-----------------------------------------------------------

- choose 'ReplicaSet ensures that desired number of PODs always run' as answer




11. Create a ReplicaSet using the replicaset-definition-1.yaml file located at /root/.
--------------------------------------------------------------------------------------
There is an issue with the file, so try to fix it.


List files in the '/root' directory
	terminal --> ls

	# result: replicaset-definition-1.yaml  replicaset-definition-2.yaml  sample.yaml

Try to create replicaset with the definition file
	terminal --> k create -f replicaset-definition-1.yaml

# result:
--------------------------------------------------
error: resource mapping not found for name: "replicaset-1" namespace: "" from "replicaset-definition-1.yaml": no matches for kind "ReplicaSet" in version "v1"
ensure CRDs are installed first
--------------------------------------------------


Edit the replicaset definition file and fix 'apiVersion' or 'kind' sections
	terminal --> vi replicaset-definition-1.yaml

replicaset-definition-1.yaml
------------------------------------------
apiVersion: apps/v1					# modify 'v1' to 'apps/v1'
kind: ReplicaSet
metadata:
  name: replicaset-1
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx
------------------------------------------
save changes - escape, :wq!, enter

Create pods with replicaset definition file replicaset-definition-1.yaml
	terminal --> k create -f replicaset-definition-1.yaml

	# result: replicaset.apps/replicaset-1 created

- click 'Çheck' button





12. Fix the issue in the replicaset-definition-2.yaml file and create a ReplicaSet using it.
--------------------------------------------------------------------------------------------
This file is located at /root/.


List files in the '/root' directory
	terminal --> ls

	# result: replicaset-definition-1.yaml  replicaset-definition-2.yaml  sample.yaml

Try to create replicaset with the definition file
	terminal --> k create -f replicaset-definition-2.yaml

# result:
--------------------------------------------------
The ReplicaSet "replicaset-2" is invalid: spec.template.metadata.labels: Invalid value: map[string]string{"tier":"nginx"}: `selector` does not match template `labels`
--------------------------------------------------


Edit the replicaset definition file and fix 'selector' section values
	terminal --> vi replicaset-definition-2.yaml

replicaset-definition-2.yaml
------------------------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-2
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: nginx				# change from 'nginx' to 'frontend'. Must match with selector/matchLabels/tier
    spec:
      containers:
      - name: nginx
        image: nginx
------------------------------------------
save changes - escape, :wq!, enter

Create pods with replicaset definition file replicaset-definition-2.yaml
	terminal --> k create -f replicaset-definition-2.yaml

	# result: replicaset.apps/replicaset-2 created

- click 'Çheck' button






13. Delete the two newly created ReplicaSets - replicaset-1 and replicaset-2
----------------------------------------------------------------------------

List replicasets
	terminal --> k get rs

# result:
--------------------------------
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       25m
replicaset-1      2         2         2       5m38s
replicaset-2      2         2         2       37s
--------------------------------	

Delete replicaset-1 and replicaset-2
	terminal --> k delete rs replicaset-1 replicaset-2
	
	# result:
	replicaset.apps "replicaset-1" deleted
	replicaset.apps "replicaset-2" deleted

- click 'Çheck' button





14. Fix the original replica set new-replica-set to use the correct busybox image.
----------------------------------------------------------------------------------
Either delete and recreate the ReplicaSet or Update the existing ReplicaSet and then delete all PODs, so new ones with the correct image will be created.

List replicasets
	terminal --> k get rs

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   4         4         0       28m

Edit the replicaset 'new-replica-set'
	terminal --> k edit rs new-replica-set

# result:
-----------------------------------------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  creationTimestamp: "2025-02-27T15:38:23Z"
  generation: 1
  name: new-replica-set
  namespace: default
  resourceVersion: "1358"
  uid: 5747609e-13a0-48f8-a8eb-8395d738e0bc
spec:
  replicas: 4
  selector:
    matchLabels:
      name: busybox-pod
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: busybox-pod
    spec:
      containers:
      - command:
        - sh
        - -c
        - echo Hello Kubernetes! && sleep 3600
        image: busybox777				# change the image from 'busybox777' to 'busybox'
        imagePullPolicy: Always
        name: busybox-container
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  fullyLabeledReplicas: 4
  observedGeneration: 1
  replicas: 4
-----------------------------------------------------------
save changes - escape, :wq!, enter

# result: replicaset.apps/new-replica-set edited


List pods
	terminal --> k get pods

	# result:
	NAME                    READY   STATUS             RESTARTS   AGE
	new-replica-set-49lsc   0/1     ImagePullBackOff   0          35m
	new-replica-set-fn6gw   0/1     ImagePullBackOff   0          35m
	new-replica-set-gnkj7   0/1     ImagePullBackOff   0          35m
	new-replica-set-jhqh2   0/1     ImagePullBackOff   0          24m


Delete all pods
	terminal --> k delete pod new-replica-set-jhqh2 new-replica-set-gnkj7 new-replica-set-fn6gw new-replica-set-49lsc

	# result:
	pod "new-replica-set-jhqh2" deleted
	pod "new-replica-set-gnkj7" deleted
	pod "new-replica-set-fn6gw" deleted
	pod "new-replica-set-49lsc" deleted


Wait few minutes for pods to be created again by the replicaset.

List pods again
	terminal --> k get pods

	# result:
	NAME                    READY   STATUS    RESTARTS   AGE
	new-replica-set-87bkr   1/1     Running   0          45s
	new-replica-set-c4627   1/1     Running   0          45s
	new-replica-set-g57jr   1/1     Running   0          45s
	new-replica-set-zvwk8   1/1     Running   0          45s

- click 'Çheck' button




15. Scale the ReplicaSet to 5 PODs.
-----------------------------------
Use kubectl scale command or edit the replicaset using kubectl edit replicaset.

List replicasets
	terminal --> k get rs

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   4         4         4       38m

Scale the replicaset to 5 with one line command
	terminal ---> k scale rs new-replica-set --replicas=5

	# result: replicaset.apps/new-replica-set scaled

OR

Edit the replicase
	terminal --> k edit rs new-replica-set

-----------------------------------------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  creationTimestamp: "2025-02-27T15:38:23Z"
  generation: 3
  name: new-replica-set
  namespace: default
  resourceVersion: "2173"
  uid: 5747609e-13a0-48f8-a8eb-8395d738e0bc
spec:
  replicas: 5						# modify replicas to 5
  selector:
    matchLabels:
      name: busybox-pod
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: busybox-pod
    spec:
      containers:
      - command:
        - sh
        - -c
        - echo Hello Kubernetes! && sleep 3600
        image: busybox
        imagePullPolicy: Always
        name: busybox-container
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 4
  fullyLabeledReplicas: 4
  observedGeneration: 3
  readyReplicas: 4
  replicas: 4				
-----------------------------------------------------------
save changes - escape, :wq!, enter

Verify the scale
	terminal --> k get rs 

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   5         5         5       40m


- click 'Çheck' button




16. Now scale the ReplicaSet down to 2 PODs.
--------------------------------------------
Use the kubectl scale command or edit the replicaset using kubectl edit replicaset.

List replicasets
	terminal --> k get rs

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   5         5         5       40m

Scale the replicaset to 2 with one line command
	terminal ---> k scale rs new-replica-set --replicas=2

	# result: replicaset.apps/new-replica-set scaled

OR

Edit the replicase
	terminal --> k edit rs new-replica-set

-----------------------------------------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  creationTimestamp: "2025-02-27T15:38:23Z"
  generation: 3
  name: new-replica-set
  namespace: default
  resourceVersion: "2173"
  uid: 5747609e-13a0-48f8-a8eb-8395d738e0bc
spec:
  replicas: 5						# modify replicas to 2
  selector:
    matchLabels:
      name: busybox-pod
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: busybox-pod
    spec:
      containers:
      - command:
        - sh
        - -c
        - echo Hello Kubernetes! && sleep 3600
        image: busybox
        imagePullPolicy: Always
        name: busybox-container
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
status:
  availableReplicas: 5
  fullyLabeledReplicas: 5
  observedGeneration: 3
  readyReplicas: 5
  replicas: 5				
-----------------------------------------------------------
save changes - escape, :wq!, enter

Verify the scale
	terminal --> k get rs 

	# result:
	NAME              DESIRED   CURRENT   READY   AGE
	new-replica-set   2         2         2       43m


- click 'Çheck' button





=================================
Section 2 25. Recap - Deployments
=================================

Deployment is parent of ReplicaSet


Definition - same as ReplicaSet's definition except 'kind' field.
----------

deployment-definition.yml
------------------------------------------
apiVersion: apps/v1
kind: Deployment		
metadata:
  name: myapp-deployment
  labels:
    app: myapp
    type: front-end

spec:
  template:			# definition of the POD is needed if replacing failed POD
    metadata:
      name: myapp-pod
      labels:
        app: myapp
        tier: front-end
    spec:
      containers:		
      - name: nginx-container	
        image: nginx

  replicas: 3			# set pod count
  selector: 
    matchLabels:
      type: front-end
------------------------------------------

Create deployment
-----------------
	terminal --> kubectl create -f deployment-definition.yml

	# result: deployment "myapp-deployment" created

	hint: create automatically replicaset and pods

List deployments
----------------
	terminal --> kubectl get deployments

List replicasets
----------------
	terminal --> kubectl get rs
	
	# replicaset will be named 'myapp-deployment-xxxxxxxxxx'

List pods
---------
	terminal --> kubectl get pods

	# pods will be created and named 'myapp-deployment-xxxxxxxxxx-xxxxx'


Deployment Commands
===================

Get all objects created by deployment creation
----------------------------------------------
	terminal --> kubectl get all


# result:

NAME 			DESIRED 	CURRENT 	UP-TO-DATE 	AVAILABLE 	AGE
deploy/myapp-deployment 3 		3 		3		3		9h		# Deploument

NAME 				DESIRED 	CURRENT 	READY		AGE			# EeplicaSet
rs/myapp-deployment-6795844b58 	3 		3 		3		9h

NAME 					READY 		STATUS		RESTARTS		AGE	# Pods
po/myapp-deployment-6795844b58-5rbjl 	1/1 		Running		0			9h
po/myapp-deployment-6795844b58-h4w55 	1/1 		Running		0			9h
po/myapp-deployment-6795844b58-lfjhv 	1/1 		Running		0			9h






=========================================
Section 2 27. Practice Test - Deployments
=========================================

Set environment alias and autocomletion
Info - https://kubernetes.io/pt-br/docs/reference/kubectl/cheatsheet/

Set alias
	terminal --> alias k=kubectl
	terminal --> complete -o default -F __start_kubectl k

Set autocompletion
	terminal --> source <(kubectl completion bash) # configuração de autocomplete no bash do shell atual, o pacote bash-completion precisa ter sido instalado primeiro.
	terminal --> echo "source <(kubectl completion bash)" >> ~/.bashrc # para adicionar o autocomplete permanentemente no seu shell bash.

We can check if autocompletion is set
	terminal --> kubectl get + (double tab)
	
	# if settings appear, then the automcompletion is set





1. How many PODs exist on the system?
-------------------------------------
In the current(default) namespace.


List pods
	terminal --> k get pods

	# result: No resources found in default namespace.

- choose '0' as asnwer




2. How many ReplicaSets exist on the system?
--------------------------------------------
In the current(default) namespace.


List replicasets
	terminal --> k get rs

	# result: No resources found in default namespace.

- choose '0' as asnwer





3. How many Deployments exist on the system?
--------------------------------------------
In the current(default) namespace.


List deployments
	terminal --> k get deploy

	# result: No resources found in default namespace.

- choose '0' as asnwer





4. How many Deployments exist on the system now?
------------------------------------------------
We just created a Deployment! Check again!


List deployments
	terminal --> k get deploy

	# result:
	NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
	frontend-deployment   0/4     4            0           26s

- choose '1' as asnwer





5. How many ReplicaSets exist on the system now?
------------------------------------------------

List replicasets
	terminal --> k get rs

	# result:
	NAME                           DESIRED   CURRENT   READY   AGE
	frontend-deployment-cd6b557c   4         4         0       69s

- choose '1' as asnwer






6. How many PODs exist on the system now?
-----------------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME                                 READY   STATUS             RESTARTS   AGE
	frontend-deployment-cd6b557c-2c955   0/1     ErrImagePull       0          103s
	frontend-deployment-cd6b557c-9pplj   0/1     ErrImagePull       0          103s
	frontend-deployment-cd6b557c-j966g   0/1     ErrImagePull       0          103s
	frontend-deployment-cd6b557c-q5d5q   0/1     ImagePullBackOff   0          103s

Print the count of pods in current namespace
	termianl --> k get pods --no-headers | wc -l

	# result: 4

- choose '4' as asnwer





7. Out of all the existing PODs, how many are ready?
----------------------------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME                                 READY   STATUS             RESTARTS   AGE
	frontend-deployment-cd6b557c-2c955   0/1     ErrImagePull       0          103s
	frontend-deployment-cd6b557c-9pplj   0/1     ErrImagePull       0          103s
	frontend-deployment-cd6b557c-j966g   0/1     ErrImagePull       0          103s
	frontend-deployment-cd6b557c-q5d5q   0/1     ImagePullBackOff   0          103s

We can see that any of the pods are not READY

- choose '0' as answer






8. What is the image used to create the pods in the new deployment?
-------------------------------------------------------------------

List deployemnts
	terminal --> k get deploy

	# result:
	NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
	frontend-deployment   0/4     4            0           4m5s

Describe deployment 'frontend-deployment'
	terminal --> k describe deploy frontend-deployment

# result:
-------------------------------------
...
Pod Template:
  Labels:  name=busybox-pod
  Containers:
   busybox-container:
    Image:      busybox888			# this is the used image
    Port:       <none>
...
-------------------------------------

- choose 'busybox888' as answer







9. Why do you think the deployment is not ready?
------------------------------------------------

List pods
	terminal --> k get pods

	# result:
	-------------------------------------------------
	NAME                                 READY   STATUS             RESTARTS   AGE
	frontend-deployment-cd6b557c-2c955   0/1     ImagePullBackOff   0          6m12s
	frontend-deployment-cd6b557c-9pplj   0/1     ImagePullBackOff   0          6m12s
	frontend-deployment-cd6b557c-j966g   0/1     ErrImagePull       0          6m12s
	frontend-deployment-cd6b557c-q5d5q   0/1     ErrImagePull       0          6m12s
	-------------------------------------------------

Show details for one of the pods
	terminal --> k describe pod frontend-deployment-cd6b557c-q5d5q

# result:
-------------------------------------------------
...
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  6m56s                  default-scheduler  Successfully assigned default/frontend-deployment-cd6b557c-q5d5q to controlplane
  Normal   Pulling    3m58s (x5 over 6m55s)  kubelet            Pulling image "busybox888"
  Warning  Failed     3m57s (x5 over 6m55s)  kubelet            Failed to pull image "busybox888": failed to pull and unpack image "docker.io/library/busybox888:latest": failed to resolve reference "docker.io/library/busybox888:latest": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Warning  Failed     3m57s (x5 over 6m55s)  kubelet            Error: ErrImagePull
  Normal   BackOff    107s (x21 over 6m55s)  kubelet            Back-off pulling image "busybox888"
  Warning  Failed     107s (x21 over 6m55s)  kubelet            Error: ImagePullBackOff
-------------------------------------------------

In 'Events' section we can see the messages.


- choose 'The image BUSYBOX888 doesn't exist' as asnwer




10. Create a new Deployment using the deployment-definition-1.yaml file located at /root/.
------------------------------------------------------------------------------------------
There is an issue with the file, so try to fix it.

List files in the '/root' directory
	terminal --> ls

	# result: deployment-definition-1.yaml  sample.yaml

Create the deployment using deployment-definition-1.yaml
	terminal --> k create -f deployment-definition-1.yaml

# result:
-----------------------------------------------------
Error from server (BadRequest): error when creating "deployment-definition-1.yaml": deployment in version "v1" cannot be handled as a Deployment: no kind "deployment" is registered for version "apps/v1" in scheme "k8s.io/apimachinery@v1.32.0-k3s1/pkg/runtime/scheme.go:100"
-----------------------------------------------------


Edit the definition file and fix the wrong fields - kind
	terminal --> vi deployment-definition-1.yaml

deployment-definition-1.yaml
------------------------------------
---
apiVersion: apps/v1
kind: Deployment			# change from 'deployment' to 'Deployment'
metadata:
  name: deployment-1
spec:
  replicas: 2
  selector:
    matchLabels:
      name: busybox-pod
  template:
    metadata:
      labels:
        name: busybox-pod
    spec:
      containers:
      - name: busybox-container
        image: busybox888
        command:
        - sh
        - "-c"
        - echo Hello Kubernetes! && sleep 3600
------------------------------------
save changes - escape, :wq!, enter

Verify changes
	terminal --> cat deployment-definition-1.yaml


Apply changes in the deployment
	terminal --> k apply -f deployment-definition-1.yaml

	# result: deployment.apps/deployment-1 created


- click 'Check' button





11. Create a new Deployment with the below attributes using your own deployment definition file.
------------------------------------------------------------------------------------------------
Name: httpd-frontend;
Replicas: 3;
Image: httpd:2.4-alpine

Show help commands for creating a deployment
	terminal --> k create deploy --help

We can use the third example
  # Create a deployment named my-dep that runs the nginx image with 3 replicas
  kubectl create deployment my-dep --image=nginx --replicas=3


Print deployment definiition file
	terminal --> k create deploy httpd-frontend --replicas=3 --image=httpd:2.4-alpine --dry-run=client -o yaml

	# k							- common kubernetes command
	# craete						- action
	# deploy						- object type
	# httpd-frontend					- object name
	# --replicas=3 						- specify replicas
	# --image=httpd:2.4-alpine				- specify used image
	# --dry-run=client					- do not create the deployemnt
	# -o yaml						- set output format to YAML						

# result:
-----------------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: httpd-frontend
  name: httpd-frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: httpd-frontend
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: httpd-frontend
    spec:
      containers:
      - image: httpd:2.4-alpine
        name: httpd
        resources: {}
status: {}
-----------------------------------------------


Save the craeted deployment definition to file dep1.yaml
	terminal --> k create deploy httpd-frontend --replicas=3 --image=httpd:2.4-alpine --dry-run=client -o yaml > dep1.yaml

	# k							- common kubernetes command
	# craete						- action
	# deploy						- object type
	# httpd-frontend					- object name
	# --replicas=3 						- specify replicas
	# --image=httpd:2.4-alpine				- specify used image
	# --dry-run=client					- do not create the deployemnt
	# -o yaml						- set output format to YAML
	# > dep1.yaml						- save the result in the dep1.yaml file

Verify file dep1.yaml creation
	terminal --> cat dep1.yaml

Craete the deployment with the created file
	terminal --> k create -f dep1.yaml

	# result: deployment.apps/httpd-frontend created

- click 'Check' button






===============================================================
Section 2 28. Certification Tip: Formatting Output with kubectl
===============================================================

The default output format for all kubectl commands is the human-readable plain-text format.

The -o flag allows us to output the details in several different formats.



kubectl [command] [TYPE] [NAME] -o <output_format>

Here are some of the commonly used formats:


1. -o jsonOutput a JSON formatted API object.

2. -o namePrint only the resource name and nothing else.

3. -o wideOutput in the plain-text format with any additional information.

4. -o yamlOutput a YAML formatted API object.

Here are some useful examples:


Output with JSON format:

terminal --> kubectl create namespace test-123 --dry-run -o json

# result:
------------------------------------
{
    "kind": "Namespace",
    "apiVersion": "v1",
    "metadata": {
        "name": "test-123",
        "creationTimestamp": null
    },
    "spec": {},
    "status": {}
}
------------------------------------


Output with YAML format:

terminal --> kubectl create namespace test-123 --dry-run -o yaml

# result:
------------------------------------
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: null
  name: test-123
spec: {}
status: {}
------------------------------------

Output with wide (additional details):

Probably the most common format used to print additional details about the object:

terminal --> kubectl get pods -o wide

# result:
------------------------------------
NAME      READY   STATUS    RESTARTS   AGE     IP          NODE     NOMINATED NODE   READINESS GATES
busybox   1/1     Running   0          3m39s   10.36.0.2   node01   <none>           <none>
ningx     1/1     Running   0          7m32s   10.44.0.1   node03   <none>           <none>
redis     1/1     Running   0          3m59s   10.36.0.1   node01   <none>           <none>
------------------------------------


For more details, refer:

https://kubernetes.io/docs/reference/kubectl/overview/

https://kubernetes.io/docs/reference/kubectl/cheatsheet/




================================
Section 2 29. Recap - Namepsaces
================================

Used for isolation, resource limits

Default - user namespace of kubernetes cluster when it is first set up
-------

kube-system - namespace for kubernetes administrative objects (DNS services, Network isolation etc). Created in different 
-----------   namespace from user's to prevent deletion by mistake.

kube-public - resources available to all users
-----------


We can connetct services in same namespace only by name
# mysql.connect("db-service")

We can connect services in different namespces by appending the name of the namespace to the name of the service
# mysql.connect("db-service.dev.svc.cluster.local")

# cluster.local - default domain name for the kubernetes cluster
# svc - subdomain for service
# dev - namespace
# db-service - the service


We can list pods in specific namespace
--------------------------------------
	terminal --> kubectl get pods --namespace=kube-system

We can create pod in specific namespace
---------------------------------------
	terminal --> kubectl create -f pod-definition.yml --namespace=dev



We can set namespace property in the pod-definition.yml file also and do not specify it in the command

pod-definition.yml
------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  namespace: dev			# specify namespace
  labels:
      app: myapp
      type: front-end
spec:
  containers:		
    - name: nginx-container	
      image: nginx		
------------------------------------------

We can create pod in specific namespace
---------------------------------------
	terminal --> kubectl create -f pod-definition.yml




Create Namespace
================

namespace-dev.yml
------------------------------------------
apiVersion: v1
kind: Namespace
metadata:
  name: dev
------------------------------------------

create namespace
----------------
option 1 - specify the name of the file
	terminal --> kubectl create -f namespace-dev.yml
	# namespace/dev created

option 2 - specify the name of the namespace
	terminal --> kubectl create namespace dev
	# namespace/dev created

How to set the specific context (default namespace)
---------------------------------------------------
	terminal --> kubectl config set-context --current --namespace=admin2406 

	# Context "default" modified.


How to switch namespace env permatently
---------------------------------------
	terminal --> kubectl config set-context --current --namespace=dev

	# now we can get pods in dev namespace by command terminal -> kubectl get pods
	# but we have to specify namespace if we want to get pods from another namespace

List pods in all namespaces
---------------------------
	terminal --> kubectl get pods --all-namespaces



Resource Quota - set resources for specific namespace
==============

compute-quota.yml
------------------------------------------
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: dev

spec:
  hard:
    pods: "10"
    request.cpu: "4"
    request.memory: 5Gi
    limits.cpu: "10"
    limits.memory: 10Gi
------------------------------------------

Create quota
------------
	terminal --> kubectl create -f compute-quota.yml





========================================
Section 2 31. Practice Test - Namespaces
========================================


Set environment alias and autocomletion
Info - https://kubernetes.io/pt-br/docs/reference/kubectl/cheatsheet/

Set alias
	terminal --> alias k=kubectl
	terminal --> complete -o default -F __start_kubectl k

Set autocompletion
	terminal --> source <(kubectl completion bash) # configuração de autocomplete no bash do shell atual, o pacote bash-completion precisa ter sido instalado primeiro.
	terminal --> echo "source <(kubectl completion bash)" >> ~/.bashrc # para adicionar o autocomplete permanentemente no seu shell bash.

We can check if autocompletion is set
	terminal --> kubectl get + (double tab)
	
	# if settings appear, then the automcompletion is set



1. How many Namespaces exist on the system?
-------------------------------------------

List namespaces
	terminal --> k get ns

Print count of namespaces
	terminal --> k get ns --no-headers | wc -l

	# result: 10

- choose '10' as answer




2. How many pods exist in the research namespace?
-------------------------------------------------

List pods in research namespace
	terminal --> k get pods -n research

	# result:
	NAME    READY   STATUS             RESTARTS      AGE
	dna-1   0/1     CrashLoopBackOff   4 (41s ago)   2m6s
	dna-2   0/1     CrashLoopBackOff   4 (26s ago)   2m6s

Show count of the pods in research namespace
	terminal --> k get pods -n research --no-headers | wc -l

	# result: 2


- choose '2' as answer




3. Create a POD in the finance namespace.
-----------------------------------------
Use the spec given below.

Name: redis
Image name: redis

Create pod in 'finance' namespace
	terminal --> k run redis --image=redis -n finance

	# result: pod/redis created

- click 'Check' button





4. Which namespace has the blue pod in it?
------------------------------------------


List pods in all namespaces
	terminal --> k get pods -A -o wide


# result:
---------------------------------------------
NAMESPACE       NAME                                      READY   STATUS             RESTARTS        AGE
...
marketing       blue                                      1/1     Running            0               5m31s
...
---------------------------------------------

- choose 'marketing' as answer





5. Access the Blue web application using the link above your terminal!!
-----------------------------------------------------------------------
From the UI you can ping other services.

Open the application

- click 'Ok' button







6. What DNS name should the Blue application use to access the database db-service in its own namespace - marketing?
--------------------------------------------------------------------------------------------------------------------
You can try it in the web application UI. Use port 6379.

List pods in marketing namespace
	terminal --> k get pods -n marketing

	# result:
	NAME       READY   STATUS    RESTARTS   AGE
	blue       1/1     Running   0          13m
	redis-db   1/1     Running   0          13m

List services in marketing namespace
	terminal --> k get svc -n marketing

	# result:
	NAME           TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
	blue-service   NodePort   10.43.110.155   <none>        8080:30082/TCP   13m
	db-service     NodePort   10.43.210.171   <none>        6379:30609/TCP   13m

Open the application and set 
	- Host name: db-service
	- Host Port: 6379
	- click 'TEST' button

	We should receive 'Success!' result

- choose 'db-service' as answer





7. What DNS name should the Blue application use to access the database db-service in the dev namespace?
--------------------------------------------------------------------------------------------------------
You can try it in the web application UI. Use port 6379.

List pods in dev namespace
	terminal --> k get pods -n dev

	# result:
	NAME       READY   STATUS    RESTARTS   AGE
	redis-db   1/1     Running   0          14m

List services in dev namespace
	terminal --> k get svc -n dev

	# result:
	NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
	db-service   ClusterIP   10.43.57.138   <none>        6379/TCP   14m

Open the application and set 
	- Host name: db-service.dev.svc.cluster.local
	- Host Port: 6379
	- click 'TEST' button

	We should receive 'Success!' result

- choose 'db-service.dev.svc.cluster.local' as answer





====================================================
Section 2 32. Certification Tip: Imperative Commands
====================================================

While you would be working mostly the declarative way - using definition files, imperative commands can help in getting one-time tasks done quickly, as well as generate a definition template easily. This would help save a considerable amount of time during your exams.

Before we begin, familiarize yourself with the two options that can come in handy while working with the below commands:

--dry-run: By default, as soon as the command is run, the resource will be created. If you simply want to test your command, use the --dry-run=client option. This will not create the resource. Instead, tell you whether the resource can be created and if your command is right.

-o yaml: This will output the resource definition in YAML format on the screen.



Use the above two in combination along with Linux output redirection to generate a resource definition file quickly, that you can then modify and create resources as required, instead of creating the files from scratch.

terminal --> kubectl run nginx --image=nginx --dry-run=client -o yaml > nginx-pod.yaml



POD
Create an NGINX Pod
	terminal --> kubectl run nginx --image=nginx

Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run)
	terminal --> kubectl run nginx --image=nginx --dry-run=client -o yaml


Deployment
Create a deployment
	terminal --> kubectl create deployment --image=nginx nginx

Generate Deployment YAML file (-o yaml). Don't create it(--dry-run)
	terminal --> kubectl create deployment --image=nginx nginx --dry-run -o yaml

Generate Deployment with 4 Replicas
	terminal --> kubectl create deployment nginx --image=nginx --replicas=4

You can also scale deployment using the kubectl scale command.
	terminal --> kubectl scale deployment nginx --replicas=4

Another way to do this is to save the YAML definition to a file and modify
	terminal --> kubectl create deployment nginx --image=nginx--dry-run=client -o yaml > nginx-deployment.yaml

You can then update the YAML file with the replicas or any other field before creating the deployment.



Service
Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379
	terminal --> kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml

(This will automatically use the pod's labels as selectors)

Or

terminal --> kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml (This will not use the pods' labels as selectors; instead it will assume selectors as app=redis. You cannot pass in selectors as an option. So it does not work well if your pod has a different label set. So generate the file and modify the selectors before creating the service)



Create a Service named nginx of type NodePort to expose pod nginx's port 80 on port 30080 on the nodes:
	terminal --> kubectl expose pod nginx --port=80 --name nginx-service --type=NodePort --dry-run=client -o yaml

(This will automatically use the pod's labels as selectors, but you cannot specify the node port. You have to generate a definition file and then add the node port in manually before creating the service with the pod.)

Or

terminal --> kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml

(This will not use the pods' labels as selectors)

Both the above commands have their own challenges. While one of it cannot accept a selector the other cannot accept a node port. I would recommend going with the `kubectl expose` command. If you need to specify a node port, generate a definition file using the same command and manually input the nodeport before creating the service.

Reference:
https://kubernetes.io/docs/reference/kubectl/conventions/





=================================================
Section 2 34. Practice Test - Imperative Commands
=================================================


1. In this lab, you will get hands-on practice with creating Kubernetes objects imperatively.
---------------------------------------------------------------------------------------------
All the questions in this lab can be done imperatively. However, for some questions, you may need to first create the YAML file using imperative methods. You can then modify the YAML according to the need and create the object using kubectl apply -f command.

- click 'Ok' button






2. Deploy a pod named nginx-pod using the nginx:alpine image.
-------------------------------------------------------------
Use imperative commands only.

Name: nginx-pod
Image: nginx:alpine

Deploy the pod
	terminal --> k run nginx-pod --image nginx:alpine
	
	# result: pod/nginx-pod created

- click 'Check' button






3. Deploy a redis pod using the redis:alpine image with the labels set to tier=db.
----------------------------------------------------------------------------------
Either use imperative commands to create the pod with the labels. Or else use imperative commands to generate the pod definition file, then add the labels before creating the pod using the file.

Pod Name: redis
Image: redis:alpine
Labels: tier=db

Show pod creation help commands
	terminal --> k run --help

We will use the fourth example
  # Start a hazelcast pod and set labels "app=hazelcast" and "env=prod" in the container
  kubectl run hazelcast --image=hazelcast/hazelcast --labels="app=hazelcast,env=prod"

Deploy the pod
	terminal --> k run redis --image redis:alpine --labels="tier=db"

	# result: pod/redis created







4. Create a service redis-service to expose the redis application within the cluster on port 6379.
--------------------------------------------------------------------------------------------------
Use imperative commands.

Service: redis-service
Port: 6379
Type: ClusterIP


Find if the redis application is a pod or deployment
	terminal --> k get pods

	# result:
	NAME        READY   STATUS    RESTARTS   AGE
	nginx-pod   1/1     Running   0          24m
	redis       1/1     Running   0          21m		# this is the pod


We have 2 options
	option 1 - create service def file with type port and edit the file to set the pod selector
	option 2 - create the service with the sepcified pod and then edit the service to set type port-'clusterip' or 'NodePort'


option 1
--------
Show service creation help commands
	terminal --> k create svc --help

Show service clusterip creation help commands
	terminal --> k create svc clusterip --help

We will use option 2
--------------------
Show help commands for service expose command
	terminal --> k expose --help

We will use the first few examples to combine our command params:
------------------------------------------------------------------
 Possible resources include (case insensitive):

 pod (po), service (svc), replicationcontroller (rc), deployment (deploy), replicaset (rs)

Examples:
  # Create a service for a replicated nginx, which serves on port 80 and connects to the containers on port 8000
  kubectl expose rc nginx --port=80 --target-port=8000

  # Create a service for a replication controller identified by type and name specified in "nginx-controller.yaml",
which serves on port 80 and connects to the containers on port 8000
  kubectl expose -f nginx-controller.yaml --port=80 --target-port=8000
  
  # Create a service for a pod valid-pod, which serves on port 444 with the name "frontend"
  kubectl expose pod valid-pod --port=444 --name=frontend
  
  # Create a second service based on the above service, exposing the container port 8443 as port 443 with the name
"nginx-https"
  kubectl expose service nginx --port=443 --target-port=8443 --name=nginx-https
------------------------------------------------------------------


Create the service definition file
	terminal --> k expose pod redis --port 6379 --name redis-service

	# result: service/redis-service exposed

Verify service creations
	terminal --> k get svc redis-service

	# result:
	NAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE
	redis-service   ClusterIP   10.43.10.45   <none>        6379/TCP   40s

Show service details
	terminal --> k describe service redis-service

# result:
------------------------------------------
Name:                     redis-service
Namespace:                default
Labels:                   tier=db
Annotations:              <none>
Selector:                 tier=db
Type:                     ClusterIP			# default type is ClusterIP, so we dont need to modify it
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.43.10.45
IPs:                      10.43.10.45
Port:                     <unset>  6379/TCP
TargetPort:               6379/TCP
Endpoints:                10.22.0.10:6379		# pod found and port set
Session Affinity:         None
Internal Traffic Policy:  Cluster
Events:                   <none>
------------------------------------------


Edit the service and set the port type if the type port is 'NodePort'
	terminal --> k edit svc redis-service

- click 'Check' button



5. Create a deployment named webapp using the image kodekloud/webapp-color with 3 replicas.
-------------------------------------------------------------------------------------------
Try to use imperative commands only. Do not create definition files.

Show create deployment help commands
	terminal --> k create deploy --help

We will use the third example
  # Create a deployment named my-dep that runs the nginx image with 3 replicas
  kubectl create deployment my-dep --image=nginx --replicas=3

Create the deployment
	terminal --> k create deploy webapp --image kodekloud/webapp-color --replicas=3
	
	# result: deployment.apps/webapp created


Verify deplyment creation
	terminal --> k get deploy

	# result:
	NAME     READY   UP-TO-DATE   AVAILABLE   AGE
	webapp   3/3     3            3           59s

- click 'Check' button





6. Create a new pod called custom-nginx using the nginx image and run it on container port 8080.
------------------------------------------------------------------------------------------------

Show create pod help commands
	terminal --> k run --help

We will use the second example
  # Start a hazelcast pod and let the container expose port 5701
  kubectl run hazelcast --image=hazelcast/hazelcast --port=5701


Create the pod
	terminal --> k run custom-nginx --image nginx --port 8080

	# result: pod/custom-nginx created

Verify the pod creation
	terminal --> k get pods

	# result:
	NAME                     READY   STATUS    RESTARTS   AGE
	custom-nginx             1/1     Running   0          25s		# created

- click 'Check' button





7. Create a new namespace called dev-ns.
----------------------------------------
Use imperative commands.

Create the namespace
	terminal --> k create ns dev-ns

	# result: namespace/dev-ns created

Verify the namespace creation
	terminal --> k get ns

	# result:
	NAME              STATUS   AGE
	default           Active   52m
	dev-ns            Active   26s		# created
	kube-node-lease   Active   52m
	kube-public       Active   52m
	kube-system       Active   52m

- click 'Check' button






8. Create a new deployment called redis-deploy in the dev-ns namespace with the redis image. It should have 2 replicas.
-----------------------------------------------------------------------------------------------------------------------
Use imperative commands.


Show create deployment help commands
	terminal --> k create deploy --help


Create the deployment
	terminal --> k create deploy redis-deploy --image redis --replicas=2 -n dev-ns

	# result: deployment.apps/redis-deploy created

Verify the deployment creation in the dev-ns namespace
	terminal --> k get deploy -n dev-ns

	# result:
	NAME           READY   UP-TO-DATE   AVAILABLE   AGE
	redis-deploy   2/2     2            2           33s

- click 'Check' button






9. Create a pod called httpd using the image httpd:alpine in the default namespace. Next, create a service of type ClusterIP by the same name (httpd). The target port for the service should be 80.
-------------------------------------------------------------------------------------------------------------------------------
Try to do this with as few steps as possible.

Task apprach
	1. Create the pod and service with one command
	OR
	1. Create the pod
	2. Create the service - 2 options
		- k expose --help command with selected pod, edit the type IP
		- k create svc command, edit the svc and set the pod selector

Show craete pod el commands
	terminal --> k run --help

Create the pod with one command
	terminal --> k run httpd --image httpd:alpine --port 80 --expose=true

	# result: 
	service/httpd created
	pod/httpd created

Verify the pod creation
	terminal --> k get pods

	# result:
	NAME                     READY   STATUS    RESTARTS   AGE
	custom-nginx             1/1     Running   0          9m41s
	httpd                    1/1     Running   0          19s		# pod created

List services
	terminal --> k get svc
	
	# result:
	NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
	httpd           ClusterIP   10.43.134.152   <none>        80/TCP     107s	# service created
	kubernetes      ClusterIP   10.43.0.1       <none>        443/TCP    65m
	redis-service   ClusterIP   10.43.10.45     <none>        6379/TCP   23m



Show service httpd details
	terminal --> k describe svc httpd

# reult:
----------------------------------------
Name:                     httpd
Namespace:                default
Labels:                   <none>
Annotations:              <none>
Selector:                 run=httpd
Type:                     ClusterIP		# default set to ClusterIP
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.43.134.152
IPs:                      10.43.134.152
Port:                     <unset>  80/TCP	# port set
TargetPort:               80/TCP
Endpoints:                10.22.0.18:80		# pod connected
Session Affinity:         None
Internal Traffic Policy:  Cluster
Events:                   <none>
----------------------------------------


- click 'Check' button




























	