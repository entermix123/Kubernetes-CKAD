CONTENT

Section 6 106. Practice Test - CornJobs
Section 6 93. Practice Test - Labels, Selectors
Section 6 94. Rolling Updates & Rollback in Deployments
Section 6 95. Updating a Deployment
Section 6 96. Demo Deployment
Section 6 98. Practice Test - Rolling Updates & Rollback
Section 6 99. Deployment Strategy - Blue Green
Section 6 100. Deployment Strategy - Canary
Section 6 102. Practice Test - Deployment Strategies
Section 6 103. Jobs
Section 6 104. CornJobs
Section 6 106. Practice Test - Jobs and CornJobs


===============================================
Section 6 91. Labels, Selectors and Annotations
===============================================

Labels and Selectors give us the possibility to group and filter object by different criteria.

Labels are properties of every object.
Selectors are the criteria we are filtering on.

example for pod-definition.yaml file
------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp
  labels:
    app: App1
    funtion: Front-End

spec:
  containers:
  -  name: simple-webapp
     image: simple-webapp
     ports:
     - containerPort: 8080
------------------------------------------

Show pod filtered with selector
	terminal --> kubectl get pods --selector app=App1




Example for replicaset
----------------------

replicaset-definition.yaml
------------------------------------------
apiVersion: v1
kind: ReplicaSet
metadata:
  name: simple-webapp
  labels:
    app: App1
    funtion: Front-End

spec:
  replicas: 3
  selector:
    matchLabels:
      app: App1			# this label have to match with template laabel
  template:
    metadata:
      labels:
        app: App1		# this labels have to cmatch with matchLabel
	function: Front-end
    spec:
      containers:
      - name: simple-webapp
        image: simple-webapp
------------------------------------------

Only if 2 labels in soec match, replicaset is created succeffully. 




example for services
--------------------

service-definition.yaml file
------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: App1		# this label must match replicaset template label
  ports:
  - protocol: TCP
    port: 80
    targetPort: 9376
------------------------------------------





Annotations - are used for additionla information and interpretation purposes
-----------


replicaset-definition.yaml
------------------------------------------
apiVersion: v1
kind: ReplicaSet
metadata:
  name: simple-webapp
  labels:
    app: App1
    funtion: Front-End
  annotations: 
      buildversion: 1.34	# annotation information

spec:
  replicas: 3
  selector:
    matchLabels:
      app: App1			
  template:
    metadata:
      labels:
        app: App1		
	function: Front-end
    spec:
      containers:
      - name: simple-webapp
        image: simple-webapp
------------------------------------------





===============================================
Section 6 93. Practice Test - Labels, Selectors
===============================================

1. We have deployed a number of PODs. They are labelled with tier, env and bu. How many PODs exist in the dev environment (env)?
--------------------------------------------------------------------------------------------------------------------------------
Use selectors to filter the output

Show all object (pods) in dev environment
	terminal --> kubectl get all --selector env=prod --no-headers

	# kubectl				- common kubernetes command
	# get					- used action
	# all					- object kind
	# --selector env=prod			- set selector for environment
	# --no-headers				- exclude headers of the result table

Show count of all filtered objects
	terminal --> kubectl get all --selector env=dev --no-headers | wc -l

	# kubectl				- common kubernetes command
	# get					- used action
	# all					- object kind
	# --selector env=dev			- set selector for environment
	# --no-headers				- exclude headers of the result table
	# | wc -l				- show count of lines in the result

Show all pods in 'dev' environment
	terminal --> k get pods --selector env=dev

	# result:
	NAME          READY   STATUS    RESTARTS   AGE
	app-1-525l2   1/1     Running   0          7m5s
	app-1-9nt54   1/1     Running   0          7m5s
	app-1-mf5wv   1/1     Running   0          7m5s
	db-1-72vr5    1/1     Running   0          7m5s
	db-1-hxjjj    1/1     Running   0          7m5s
	db-1-njc7d    1/1     Running   0          7m5s
	db-1-wjfzv    1/1     Running   0          7m5s

Show count of the pods in 'dev' environment
	terminal --> k get pods --selector env=dev --no-headers | wc -l

	# result: 7

- choose '7' as answer



2. How many PODs are in the finance business unit (bu)?
-------------------------------------------------------

Show pods in bu finance
	terminal --> kubectl get pods --selector bu=finance

	# kubectl				- common kubernetes command
	# get					- used action
	# pods					- object kind
	# --selector bu=finance			- set selector for business unit


Show count
	terminal --> kubectl get pods --selector bu=finance --no-headers | wc -l

	# kubectl				- common kubernetes command
	# get					- used action
	# pods					- object kind
	# --selector bu=finance			- set selector for environment
	# --no-headers				- exclude headers of the result table
	# | wc -l				- show count of lines in the result

- choose '6' as answer



3. How many objects are in the prod environment including PODs, ReplicaSets and any other objects?
--------------------------------------------------------------------------------------------------

Show all object in prod environment
	terminal --> kubectl get all --selector env=prod --no-headers | wc -l

	# kubectl				- common kubernetes command
	# get					- used action
	# all					- object kind
	# --selector env=prod			- set selector for environment
	# --no-headers				- exclude headers of the result table
	# | wc -l				- show count of lines in the result

- choose '7' as answer



4. Identify the POD which is part of the prod environment, the finance BU and of frontend tier?
-----------------------------------------------------------------------------------------------

Show the pod in prod environment, finance bu and frontend tier
	terminal --> kubectl get pods --selector env=prod,bu=finance,tier=frontend

	# kubectl				- common kubernetes command
	# get					- used action
	# all					- object kind
	# --selector 				- selector
	# env=prod				- env=rpod selector
	# bu=finance				- bu=finance selector
	# tier=frontend				- tier-frontend selector

	# result:
	NAME          READY   STATUS    RESTARTS   AGE
	app-1-zzxdf   1/1     Running   0          11m

- choose 'app-1-zzxdf' as answer



5. A ReplicaSet definition file is given replicaset-definition-1.yaml. Attempt to create the replicaset; you will encounter an issue with the file. Try to fix it.
------------------------------------------------------------------------------------------------------------------------------
Once you fix the issue, create the replicaset from the definition file.

Trye to create the replicaset
	ternubal --> k create -f replicaset-definition-1.yaml

# result:
The ReplicaSet "replicaset-1" is invalid: spec.template.metadata.labels: Invalid value: map[string]string{"tier":"nginx"}: `selector` does not match template `labels`


Print the replicaset definition file
	terminal --> cat replicaset-definition-1.yaml

replicaset-definition-1.yaml
-----------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
   name: replicaset-1
spec:
   replicas: 2
   selector:
      matchLabels:
        tier: front-end			# this is different from template labels
   template:
     metadata:
       labels:
        tier: nginx			# this is different from replicaset selector
     spec:
       containers:
       - name: nginx
         image: nginx
-----------------------------



Edit the replicaset definition file
	terminal --> vi replicaset-definition-1.yaml

replicaset-definition-1.yaml
-----------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
   name: replicaset-1
spec:
   replicas: 2
   selector:
      matchLabels:
        tier: nginx
   template:
     metadata:
       labels:
        tier: nginx
     spec:
       containers:
       - name: nginx
         image: nginx
-----------------------------
save changes - escape, :wq!, enter


Try to create the replicaset again
	ternubal --> k create -f replicaset-definition-1.yaml

	# result: replicaset.apps/replicaset-1 created


- cklick 'Check' button




=======================================================
Section 6 94. Rolling Updates & Rollback in Deployments
=======================================================


Explain Rollout and Versioning
==============================

When we first create a deployment (example: nginx:1.7.0) it creates a Rollout. A new rollout create a new deployment revision - Revision 1.

When the application container is updated (nginx:1.7.1), a new Rollout is triggered and a new deployment revision is created - Revision 2.


Rollout Commands
----------------

Show rollouts status
	terminal --> kubectl rollout status deployment/myapp-deployment

	# kubectl 				- common kubernetes command
	# rollout status			- information about obejct required
	# deployment/myapp-deployment		- taget object


Show revisions and history of rollout
	terminal --> kubectl rollout history deployment/myapp-deployment

	# kubectl 				- common kubernetes command
	# rollout history			- information about obejct required
	# deployment/myapp-deployment		- taget object



Deployment Strategies
=====================

1. Reacreate Strategy - Destroy all application pods at ones and create all pods again with the new version
	- this creates a downtime of the app, because there is period of no working application 
	- not the default deployment strategy
	- not recommended


2. Rolling Update Strategy - take down and update each pod one by one
	- this strategy do not have downtime period
	- default kubernetes strategy
	- recommended


How we update deployment
========================

Make changes to the deployemnt-definition file (declarative approach)

deployment-definition.yaml
------------------------------------------------
apiVersion: v1
kind: Deployment
metadata:
  name: myapp-deployment
  labels:
    app: myapp
    type: front-end
spec:
  template:
    metadata:
      name: myapp-pod
      labels:
	app: myapp
	type: front-end
    spec:
      containers:
      - name: nginx-container
	image: nginx:1.7.1		# add version
  replicas: 3
  selector:
    matchLabels:
       type: front-end
------------------------------------------------


Update command we use usually
	temrinal --> kubectl apply -f deployment-definition.yaml

	# result: deployment "myapp-deployment" configured

	# new rollout is triggered 
	# new revision of the deployment is created


Image update command (imperative approach)
	terminal --> kubectl set image deployemnt/myapp-deployment nginx-container=nginx:1.9.1

	# this command DO NOT update deployemnt-definition.yaml file !!! Not Recommneded !!!



Find what strategy was used in update
-------------------------------------

Show deployemnt details
	terminal --> kubectl describe deployment my-depoyment

Under 'StrategyType' field we can see 'Recreate' or 'RollingUpdate' values

Also messages with information about setting replicas to '0' laso means that 'Recreate' strategy was used



How RollingUpdate is working?
-----------------------------

When new deployment is created with 5 replicas, it first creates a ReplicaSet automatically that creates 5 replicas.

When Upgrade is made a new ReplicaSet is created. The two replicasets are working simultaneously. Old ReplicaSet deletes one pod and the new ReplicaSet create one pod and so on.

We can check old and new replicaset object
	terminal --> k get replicasets


How Rollback work?
------------------

Star a rollback
	terminal --> kubectl rollout undo deployment/myapp-deployment

	# the deployment will destroy the pods in the last ReplicaSet and restore the pods in the previous ReplicaSet

We can trace this process by listing ReplicaSets before and after a rollback command
	terminal --> kubectl get replicasets



Commands Summarize
------------------

Craete deployemnt
	terminal --> kubectl create deployment -f deployment-definition.yaml

List deployments
	terminal --> kubectl get deployments

Update deployemnts
	terminal --> kubectl apply -f deployment-definition.yaml			# recommended
	or
	terminal --> kubectl set image deployemnt/myapp-deployment nginx=nginx:1.9.1	# not recommended, DO NOT update def file

Show deployemnt status
	terminal --> kubect rollout status deployemnt/myapp-deployment

Show deployment history
	terminal --> kubectl rollout history deployemnt/myapp-deployment




===================================
Section 6 95. Updating a Deployment
===================================

Here are some handy examples related to updating a Kubernetes Deployment:

Creating a deployment, checking the rollout status and history:
---------------------------------------------------------------
In the example below, we will first create a simple deployment and inspect the rollout status and the rollout history:

master $ --> kubectl create deployment nginx --image=nginx:1.16

	# result: deployment.apps/nginx created
 
master $ --> kubectl rollout status deployment nginx

	# result:
	Waiting for deployment "nginx" rollout to finish: 0 of 1 updated replicas are available...
	deployment "nginx" successfully rolled out
 
 
master $ --> kubectl rollout history deployment nginx

	# result:
	deployment.extensions/nginx
	REVISION CHANGE-CAUSE
	1     <none>
 

Using the --revision flag:
--------------------------
Here the revision 1 is the first version where the deployment was created.

You can check the status of each revision individually by using the --revision flag:

master $ --> kubectl rollout history deployment nginx --revision=1

# result: 
deployment.extensions/nginx with revision #1
Pod Template:
 Labels:    app=nginx    pod-template-hash=6454457cdb
 Containers:  nginx:  Image:   nginx:1.16
  Port:    <none>
  Host Port: <none>
  Environment:    <none>
  Mounts:   <none>
 Volumes:   <none>



Using the --record flag:
------------------------
You would have noticed that the "change-cause" field is empty in the rollout history output. We can use the --record flag to save the command used to create/update a deployment against the revision number.

master $ --> kubectl set image deployment nginx nginx=nginx:1.17 --record

# result:
deployment.extensions/nginx image updated

 
master $ --> kubectl rollout history deployment nginx

# result:
deployment.extensions/nginx
 
REVISION CHANGE-CAUSE
1     <none>
2     kubectl set image deployment nginx nginx=nginx:1.17 --record=true


You can now see that the change-cause is recorded for the revision 2 of this deployment.

Let's make some more changes. In the example below, we are editing the deployment and changing the image from nginx:1.17 to nginx:latest while making use of the --record flag.

master $ --> kubectl edit deployments. nginx --record

# result: deployment.extensions/nginx edited
 

master $ --> kubectl rollout history deployment nginx

# result:
REVISION CHANGE-CAUSE
1     <none>
2     kubectl set image deployment nginx nginx=nginx:1.17 --record=true
3     kubectl edit deployments. nginx --record=true
 
 
master $ --> kubectl rollout history deployment nginx --revision=3

# result: 
deployment.extensions/nginx with revision #3
 
Pod Template: Labels:    app=nginx
    pod-template-hash=df6487dc Annotations: kubernetes.io/change-cause: kubectl edit deployments. nginx --record=true
 
 Containers:
  nginx:
  Image:   nginx:latest
  Port:    <none>
  Host Port: <none>
  Environment:    <none>
  Mounts:   <none>
 Volumes:   <none>
 


Undo a change:
--------------
Lets now rollback to the previous revision:

controlplane $ --> kubectl rollout history deployment nginx

# result:
deployment.apps/nginx 
REVISION  CHANGE-CAUSE
1         <none>
3         kubectl edit deployments.apps nginx --record=true
4         kubectl set image deployment nginx nginx=nginx:1.17 --record=true
 
 
 
controlplane $ --> kubectl rollout history deployment nginx --revision=3

# result:
deployment.apps/nginx with revision #3
Pod Template:
  Labels:       app=nginx
        pod-template-hash=787f54657b
  Annotations:  kubernetes.io/change-cause: kubectl edit deployments.apps nginx --record=true
  Containers:
   nginx:
    Image:      nginx:latest
    Port:      <none> 
    Host Port:  <none>
    Environment: <none>       
    Mounts:     <none>
  Volumes:      
 
controlplane $ --> kubectl describe deployments. nginx | grep -i image:

# result:
    Image:        nginx:1.17
 



With this, we have rolled back to the previous version of the deployment with the image = nginx:1.17.

controlplane $ --> kubectl rollout history deployment nginx --revision=1

# result:
deployment.apps/nginx with revision #1
Pod Template:
  Labels:       app=nginx
        pod-template-hash=78449c65d4
  Containers:
   nginx:
    Image:      nginx:1.16
    Port:       <none> 
    Host Port:  <none>
    Environment: <none>     
    Mounts:     <none>
  Volumes:      
 

controlplane $ --> kubectl rollout undo deployment nginx --to-revision=1

# result:
deployment.apps/nginx rolled back
To rollback to specific revision we will use the --to-revision flag.
With --to-revision=1, it will be rolled back with the first image we used to create a deployment as we can see in the rollout history output.

controlplane $ --> kubectl describe deployments. nginx | grep -i image:

# result:
Image: nginx:1.16



=============================
Section 6 96. Demo Deployment
=============================

We will look at updates and rollbacks in deployments

Show all existing objects on the node
	master node terminal --> kubectl get all
	
	# result: 
	NAME 		TYPE		CLUSTER-IP 	EXTERNAL-IP	PORT(S)		AGE
	svc/kubernetes	ClusterIP	10.96.0.1	<none>		443/TCP		2d


Create new deployment
	master node terminal --> kubectl create -f deployment-definition.yaml
	
	# result: deployment "myapp-deployment" created


Show update status - creates rollouts
	master node terminal --> kubectl rollout status deployment/myapp-deployment

	# result:
	Waiting for rollout to finish: 2 of 6 updated replicas are available...
	Waiting for rollout to finish: 3 of 6 updated replicas are available...
	Waiting for rollout to finish: 4 of 6 updated replicas are available...
	Waiting for rollout to finish: 5 of 6 updated replicas are available...
	deployment "myapp-deployment" successfully rolled out


Show update history
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		<none>

If we delete the deployment
	master node terminal --> kubectl delete deployment myapp-deployment
	
	# result: deployment "myapp-deployment" deleted

Wait until all objects connected with the deployemnt to be deleted.

And recreate the deployment with additional command flag (--record)
	master node terminal --> k create -f deployment-definition.yaml --record

	# result: "myapp-deployment" created

Show deployment status
	master node terminal --> kubectl rollout status deployment/myapp-deployment

	# result:
	Waiting for rollout to finish: 1 of 6 updated replicas are available...
	Waiting for rollout to finish: 2 of 6 updated replicas are available...
	Waiting for rollout to finish: 3 of 6 updated replicas are available...
	Waiting for rollout to finish: 4 of 6 updated replicas are available...
	Waiting for rollout to finish: 5 of 6 updated replicas are available...
	deployment "myapp-deployment" successfully rolled out


Show deployment history
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		kubectl create --filename=deployment-definition.yaml --record=true


We will make a small change to our deployment - downgrade of the used nginx image (because by default it takes the latest version)
	terminal --> vi deployment-definition.yaml

deployment-definition.yaml
-------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  labels:
    app: myapp
    type: front-end
spec:
  template:
    metadata:
      name: myapp-pod
      labels:
	app: myapp

    spec:
      containers:
	- name: nginx-container
	  image: nginx:1.12			# added ':1.12'

  replicas: 6

  selector:
    matchLabels:
      app: myapp
-------------------------------------
save changes - escape, :wq!, enter


Apply the changes of the deployment
	terminal --> kubectl apply -f deployment-definition.yaml
	
	# result: deployment "myapp-deployment" configured


Show deployment status
	master node terminal --> kubectl rollout status deployment/myapp-deployment

	# result:
	Waiting for rollout to finish: 3 of 6 updated replicas are updated...
	Waiting for rollout to finish: 4 of 6 updated replicas are updated...
	Waiting for rollout to finish: 5 of 6 updated replicas are updated...
	...
	deployment "myapp-deployment" successfully rolled out


List deployments
	master node terminal --> kubectl get deployment

	# result:
	NAME			DESIRED		CURRENT		UP-TO-DATE	AVAILABLE	AGE
	myapp-deployment	6		6		6		6		4m


List pods
	master node terminal --> kubectl get pods


Show deployment details
	master node terminal --> kubectl describe deploymnet

	# we can see the image in 'Image: nginx:1.12' line


Show deployment history again
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		kubectl create --filename=deployment-definition.yaml --record=true
	2		kubectl apply --filename=deployment-definition.yaml --record=true	

	# We can see that new revision is added with the executed command



Now we will change the image (nginx:1.12-perl) with imperative approach - with one command
	master node terminal --> kubectl set image deployment/myapp-deployment nginx-container=nginx:1.12-perl

	# result: deployment "myapp-deployment" image updated

	# This command DO NOT update the deployment definition file !


Create new rollout
	master node terminal --> kubectl rollout status deployment/myapp-deployment

	# result:
	Waiting for rollout to finish: 3 of 6 updated replicas are updated...
	Waiting for rollout to finish: 4 of 6 updated replicas are updated...
	Waiting for rollout to finish: 5 of 6 updated replicas are updated...
	...
	deployment "myapp-deployment" successfully rolled out


Show deployment history after imperative approach update
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		kubectl create --filename=deployment-definition.yaml --record=true
	2		kubectl apply --filename=deployment-definition.yaml --record=true
	3		kubectl set image deployment/myapp-deployment nginx-container=nginx:1.12-perl

	# We can see that new revision with the executed command is added


Show deployment details
	master node terminal --> kubectl describe deploymnet

	# we can see the image in 'Image: nginx:1.12-perl' line



Now we will rollback the last change
	master node terminal --> kubectl rollout undo deployment/myapp-deployment

	# result: deployment "myapp-deployment"


Show deployment status
	master node terminal --> kubectl rollout status deployment/myapp-deployment

	# result:
	Waiting for rollout to finish: 3 of 6 updated replicas are updated...
	Waiting for rollout to finish: 4 of 6 updated replicas are updated...
	Waiting for rollout to finish: 5 of 6 updated replicas are updated...
	...
	deployment "myapp-deployment" successfully rolled out


Show deployment history after rollback
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		kubectl create --filename=deployment-definition.yaml --record=true
	3		kubectl set image deployment/myapp-deployment nginx-container=nginx:1.12-perl
	4		kubectl apply --filename=deployment-definition.yaml --record=true

	# We can see that old revision is deleted (2) and added as new one (4) with the executed command


Show deployment details
	master node terminal --> kubectl describe deploymnet

	# we can see the updated image in 'Image: nginx:1.12' line is back to previous version - 2



We will simulate error by setting image of the nginx that do not exist
----------------------------------------------------------------------

Edit the deployment definition file
	master node terminal --> vi deployment-definition.yaml

deployment-definition.yaml
-------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  labels:
    app: myapp
    type: front-end
spec:
  template:
    metadata:
      name: myapp-pod
      labels:
	app: myapp

    spec:
      containers:
	- name: nginx-container
	  image: nginx:1.12			# changed to 1.5-err	

  replicas: 6

  selector:
    matchLabels:
      app: myapp
-------------------------------------
save changes - escape, :wq!, enter


Try to apply changes
	master node terminal --> kubectl apply -f deployment-definition.yaml --record

	# result: deployment "myapp-deployment" configured


Monitor the status of the update
	master node terminal --> kubectl rollout status deployment/myapp-deployment

	# result:
	Waiting for rollout to finish: 3 of 6 updated replicas are updated...
	
	# update is stuck
	# escape the monitoring with ctrl+c


List deployments
	master node terminal --> kubectl get deployment

	# result:
	NAME			DESIRED		CURRENT		UP-TO-DATE	AVAILABLE	AGE
	myapp-deployment	6		8		3		5		11m

	# trying to update but do not finds the image


We can list the pods to check on the status of every one of them
	master node terminal --> kubectl get pods

	# result:
	NAME					READY		STATUS			RESTARTS	AGE
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	0/1		ImagePullBackoff	0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	0/1		ImagePullBackoff	0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	0/1		ImagePullBackoff	0		4m

	# We can see that 3 of the pods are in not ready state with status 'ImagePullBackoff'
	# Kubernetes acts proactivelly
		- teminates only one of the working pods
		- tryied to create 3 new pods with the wrong image and stop


Show deployment history
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		kubectl create --filename=deployment-definition.yaml --record=true
	3		kubectl set image deployment/myapp-deployment nginx-container=nginx:1.12-perl
	4		kubectl apply --filename=deployment-definition.yaml --record=true
	5		kubectl apply --filename=deployment-definition.yaml --record=true

	# We can see that new revision is created (5) with the executed command


We now will rollback (undo) the last image change (with the wrong image) and see the result - rollback
	master node terminal --> kubectl rollout undo deployment/myapp-deployment

	# result: deployment "myapp-deployment"


Show deployment history after rollback
	master node terminal --> kubectl rollout history deployment/myapp-deployment

	# result:
	deployments "myapp-deployment"
	REVISION	CHANGE-CAUSE
	1		kubectl create --filename=deployment-definition.yaml --record=true
	3		kubectl set image deployment/myapp-deployment nginx-container=nginx:1.12-perl
	4		kubectl apply --filename=deployment-definition.yaml --record=true
	5		kubectl apply --filename=deployment-definition.yaml --record=true
	6		kubectl apply --filename=deployment-definition.yaml --record=true

	# We can see that new revision is created (6) with the executed command


Show deployment details
	master node terminal --> kubectl describe deploymnet

	# we can see the updated image in 'Image: nginx:1.12' line is back to previous version


We can list the pods 
	master node terminal --> kubectl get pods

	# result:
	NAME					READY		STATUS			RESTARTS	AGE
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m
	myapp-deployment-xxxxxxxxxx-xxxxx	1/1		Running			0		4m

	# now all pods are in runnign state


========================================================
Section 6 98. Practice Test - Rolling Updates & Rollback
========================================================

We will use 'k' alias for 'kubectl' command. We can see all alias with
	terminal --> alias 

1. We have deployed a simple web application. Inspect the PODs and the Services
-------------------------------------------------------------------------------
Wait for the application to fully deploy and view the application using the link called Webapp Portal above your terminal.

List pods
	terminal --> k get pods

List deployemnts
	terminal --> k get deploy

Click on 'Webapp Portal' above top right corner of the console
	- window with the working app should open

- click 'Ok' button



2. What is the current color of the web application?
----------------------------------------------------
Access the Webapp Portal.

Click on 'Webapp Portal' above top right corner of the console
	- window with the working app should open

- choose 'blue' as answer (or whatever color is the background of the application)



3. Run the script named curl-test.sh to send multiple requests to test the web application. Take a note of the output.
----------------------------------------------------------------------------------------------------------------------
Execute the script at /root/curl-test.sh.


Run command:
	terminal --> ./curl-test.sh

	# result:
	Hello, Application Version: v1 ; Color: blue OK

	Hello, Application Version: v1 ; Color: blue OK

	Hello, Application Version: v1 ; Color: blue OK
	...

- click 'Ok' button




4. Inspect the deployment and identify the number of PODs deployed by it
------------------------------------------------------------------------

List deployments
	terminal --> k get deploy

	# result:
	NAME       READY   UP-TO-DATE   AVAILABLE   AGE
	frontend   4/4     4            4           106s

- choose '4' as answer



5. What container image is used to deploy the applications?
-----------------------------------------------------------

List deployemnts
	terminal --> k get deploy

	# result:
	NAME       READY   UP-TO-DATE   AVAILABLE   AGE
	frontend   4/4     4            4           2m27s

Show used image in the target deployemnt
	terminal --> k describe deploy frontend | grep Image

	# result:     Image:         kodekloud/webapp-color:v1

OR 

List pods
	terminal --> k get pods

Show image used in one of the pods
	terminal --> k describe pod frontend-7b5df69f4-bms77 | grep Image

- choose 'kodekloud/webapp-color:v1' as answer



6. Inspect the deployment and identify the current strategy
-----------------------------------------------------------

List deployemnts
	terminal --> k get deploy

Show used strategy in the target deployemnt
	terminal --> k describe deploy frontend | grep StrategyType

- choose 'RollingUpdate' as answer



7. If you were to upgrade the application now what would happen?
----------------------------------------------------------------

- choose 'PODs are upgraded few at a time' as answer



8. Let us try that. Upgrade the application by setting the image on the deployment to kodekloud/webapp-color:v2
---------------------------------------------------------------------------------------------------------------
Do not delete and re-create the deployment. Only set the new image name for the existing deployment.

Task approach
	1. Edit the existing deployment and apply changes

List deployments
	terminal --> k get deploy

	# result:
	NAME       READY   UP-TO-DATE   AVAILABLE   AGE
	frontend   4/4     4            4           5m49s


Option 1:
---------
Update deployemnt configs
	terminal --> k edit deploy frontend

frontedn deployment
------------------------------------------------
...
spec:
  minReadySeconds: 20
  progressDeadlineSeconds: 600
  replicas: 4
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: webapp
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: webapp
    spec:
      containers:
      - image: kodekloud/webapp-color:v2			# changed
        imagePullPolicy: IfNotPresent
...
------------------------------------------------
save changes - escape, :wq!, enter

# result: deployment.apps/frontend edited

Verify the change
	terminal --> k describe deploy frontend

	# We can see changed line 'Image:         kodekloud/webapp-color:v2'


Option 2:
---------
Show details of the deployment and copy the container name
	terminal --> k describe deployment frontend

	# result:
	-----------------
	...
	  Containers:
	   simple-webapp:
	...
	-----------------

	# container name is 'simple-webapp'


Update the deployment without updating the deployment config
	terminal --> k set image deploy frontend simple-webapp=kodekloud/webapp-color:v2

	# k 						- common kubernetes command
	# set image					- update deployment image
	# deploy					- type object
	# frontend					- target object name
	# simple-webapp=kodekloud/webapp-color:v2	- container name and imagename

Verify the change
	terminal --> k describe deploy frontend


- click 'Check' button




9. Run the script curl-test.sh again. Notice the requests now hit both the old and newer versions. However none of them fail.
-----------------------------------------------------------------------------------------------------------------------------
Execute the script at /root/curl-test.sh.

Run tests
	terminal --> ./curl-test.sh

	# result:
	Hello, Application Version: v2 ; Color: green OK

	Hello, Application Version: v2 ; Color: green OK

	Hello, Application Version: v2 ; Color: green OK
	...

	# we can see that there is a new colors in the tests results
	# if we run the tests few times, all colors wull be changed 
	# that is how rollingupdate work

- click 'Ok' button



10 . Up to how many PODs can be down for upgrade at a time
----------------------------------------------------------
Consider the current strategy settings and number of PODs - 4

List pods
	terminal --> k get pods

	# result:
	NAME                        READY   STATUS    RESTARTS   AGE
	frontend-854b57fbbf-ccrbc   1/1     Running   0          6m56s
	frontend-854b57fbbf-fts95   1/1     Running   0          6m34s
	frontend-854b57fbbf-nqzpn   1/1     Running   0          6m56s
	frontend-854b57fbbf-tws7p   1/1     Running   0          6m34s

	# we have 4 pods


Show details about the deployment
	terminal --> k describe deploy frontend

# in the result We have fields:
-----------------------------------
...
	MinReadySeconds:        20
	RollingUpdateStrategy:  25% max unavailable, 25% max surge
...
-----------------------------------

- choose '1' as answer



11. Change the deployment strategy to Recreate
----------------------------------------------
Delete and re-create the deployment if necessary. Only update the strategy type for the existing deployment.


List deployemnts
	terminal --> k get deploy
	
	# result:
	NAME       READY   UP-TO-DATE   AVAILABLE   AGE
	frontend   4/4     4            4           15m


Update deployemnt configs
	terminal --> k edit deploy frontend

frontedn deployment
------------------------------------------------
...
spec:
  minReadySeconds: 20
  progressDeadlineSeconds: 600
  replicas: 4
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: webapp
  strategy:						# removed additional lines
    type: Recreate					# changed
  template:
...
------------------------------------------------
save changes - escape, :wq!, enter

# result: deployment.apps/frontend edited


Verify the change
	terminal --> k describe deploy frontend | grep StrategyType

	# result: StrategyType:       Recreate


- click 'Check' button




12. Upgrade the application by setting the image on the deployment to kodekloud/webapp-color:v3
-----------------------------------------------------------------------------------------------
Do not delete and re-create the deployment. Only set the new image name for the existing deployment.

List deployments
	terminal --> k get deploy

	# result:
	NAME       READY   UP-TO-DATE   AVAILABLE   AGE
	frontend   4/4     4            0           20m


Option 1:
---------
Update deployemnt configs
	terminal --> k edit deploy frontend

frontedn deployment
------------------------------------------------
...
spec:
  minReadySeconds: 20
  progressDeadlineSeconds: 600
  replicas: 4
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: webapp
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        name: webapp
    spec:
      containers:
      - image: kodekloud/webapp-color:v3			# changed		
        imagePullPolicy: IfNotPresent
...
------------------------------------------------
save changes - escape, :wq!, enter

# result: deployment.apps/frontend edited


Verify the change
	terminal --> k describe deploy frontend | grep Image

	# result:     Image:         kodekloud/webapp-color:v3


Option 2:
---------
Show details of the deployment and copy the container name
	terminal --> k describe deployment frontend

	# container name is 'simple-webapp'

Update the deployment without updating the deployment config
	terminal --> k set image deploy frontend simple-webapp=kodekloud/webapp-color:v3

	# k 						- common kubernetes command
	# set image					- update deployment image
	# deploy					- type object
	# frontend					- target object name
	# simple-webapp=kodekloud/webapp-color:v3	- container name and imagename

Verify the change
	terminal --> k describe deploy frontend | grep Image

	# result:     Image:         kodekloud/webapp-color:v3


- click 'Check' button



13. Run the script curl-test.sh again. Notice the failures. Wait for the new application to be ready. Notice that the requests now do not hit both the versions
----------------------------------------------------------------------------------------------------------------------------------
Execute the script at /root/curl-test.sh.


Run tests
	terminal --> ./curl-test.sh

	# result:
	Hello, Application Version: v3 ; Color: red OK

	Hello, Application Version: v3 ; Color: red OK

	Hello, Application Version: v3 ; Color: red OK
	...

	# we can see that all test result changed to red at once
	# that is how recrate strategy work

- click 'Ok' button



==============================================
Section 6 99. Deployment Strategy - Blue Green
==============================================




===========================================
Section 6 100. Deployment Strategy - Canary
===========================================

====================================================
Section 6 102. Practice Test - Deployment Strategies
====================================================

===================
Section 6 103. Jobs
===================

=======================
Section 6 104. CornJobs
=======================

================================================
Section 6 106. Practice Test - Jobs and CornJobs
================================================








