CONTENT

Section 4 75. Multi-Container Pods
Section 4 77. Practice Test - Multi-Container Pods
Section 4 78. Init Containers
Section 4 80. Practice Test - Init Containers


==================================
Section 4 75. Multi-Container Pods
==================================

W will look over different patterns of multi-container pods in Kubernetes such as
	- Ambassador
	- Adapter
	- Sidecar


The idea if decoupling large monolithic application in to subcomponents know as microservices enables us to develop and deploy a set of independent small and reusable code. This architecture then can help us scale up, down as well as modify each service as required as suppose to modify the entire applicatin.

At times we need 2 services to work together (Web Server and Log Service). We need one instance of both paired together. We don't want to merge and mesh the code of the two services as each of them target different functionalities and we want them to be developed and deployed separately. 

We need one agent (log agent) per web server instance paired together that can scale up and down together. That is why we have multi-container pods that share the same lifecycle - created together and destroyed together. They share the same network space (can refer to each other as localhost) and they have access to the same storage volumes. This way we don't have to establish volume sharing or services between the pods to enable communication between them.

Example multi-container pod

pod-definition.yaml
------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp
  labels:
    name: simple-webapp
spec:
  containers:
  - name: simple-webapp
    image: simple-webapp
    ports:
      - containerPort: 8080

  - name: log-agent
    image: log-agent
------------------------------------------



Design Patterns
---------------

1. Sidecar - Web server with log agent to collect logs and ned them to central Log Server.   

2. Adapter - Adapater container converts the logs into a common format. Adapter container process the logs before sending them to the central logs server.

3. Ambassador - Differentiate the connections to the different DBs (Dev, Test, Prod)




==================================================
Section 4 77. Practice Test - Multi-Container Pods
==================================================


1. Identify the number of containers created in the red pod.
------------------------------------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME        READY   STATUS              RESTARTS   AGE
	app         0/1     ContainerCreating   0          36s
	fluent-ui   1/1     Running             0          36s
	red         0/3     ContainerCreating   0          24s		# target pod with 3 containers in it (0/3)


Show information for 'red' pod
	terminal --> k describe pod red

# result:
-----------------------------------------------------
...
IPs:              <none>
Containers:
  apple:				# fisrt container in the pod
    Container ID:  
    Image:         busybox
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      4500
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rph42 (ro)
  wine:					# second container in the pod
    Container ID:  
    Image:         busybox
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      4500
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rph42 (ro)
  scarlet:				# third container in the pod
    Container ID:  
    Image:         busybox
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      4500
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rph42 (ro)
Conditions:
...
-----------------------------------------------------

- choose '3' as answer




2. Identify the name of the containers running in the blue pod.
---------------------------------------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME        READY   STATUS              RESTARTS   AGE
	app         1/1     Running   0          4m7s
	blue        2/2     Running   0          59s			# target container
	fluent-ui   1/1     Running   0          4m7s
	red         3/3     Running   0          3m55s



Show information for 'blue' pod
	terminal --> k describe pod blue

# result
-----------------------------------------------------
...
Containers:
  teal:				# first container name
    Container ID:  containerd://5f1aefa52b665ec04a5e7be6d4cadb79a20bfae154d792c0d4f617ec80a50e69
    Image:         busybox
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      4500
    State:          Running
      Started:      Fri, 07 Mar 2025 10:12:51 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-sbgsb (ro)
  navy:				# second container name
    Container ID:  containerd://03ef762050bc5a1a9577508a034af9c0eee5744e86a6cd8cf99f922eb165e63b
    Image:         busybox
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      4500
    State:          Running
      Started:      Fri, 07 Mar 2025 10:12:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-sbgsb (ro)
Conditions:
...
-----------------------------------------------------


- choose 'teal & navy' as answer




3. Create a multi-container pod with 2 containers.
--------------------------------------------------
Use the spec given below:

If the pod goes into the crashloopbackoff then add the command sleep 1000 in the lemon container.

Name: yellow

Container 1 Name: lemon
Container 1 Image: busybox
Container 2 Name: gold
Container 2 Image: redis

Print pod-definition file for pod with the first required container
	terminal --> k run yellow --image busybox --dry-run=client -o yaml

# result:
--------------------------------------
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: yellow
  name: yellow
spec:
  containers:
  - image: busybox
    name: yellow
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
--------------------------------------


Save the pod-definition file
	terminal --> k run yellow --image busybox --dry-run=client -o yaml > yellow.yaml

Edit the yellow pod-definition file to add the second container
	terminal --> vi yellow.yaml


# result
--------------------------------------
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: yellow
  name: yellow
spec:
  containers:
  - image: busybox
    name: lemon
    resources: {}
    command: [ "sleep", "1000" ]
  - name: gold
    image: redis
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
--------------------------------------
save changes - escape, :wq!, enter


Create the pod with required containers
	termianl --> k create -f yellow.yaml	
		
	# result: pod/yellow created


Verify the pod creation
	terminal --> k get pods

	# result:
	NAME        READY   STATUS    RESTARTS   AGE
	app         1/1     Running   0          25m
	blue        2/2     Running   0          22m
	fluent-ui   1/1     Running   0          25m
	red         3/3     Running   0          25m
	yellow      2/2     Running   0          47s		# pod created

Show pod details
	terminal --> k describe pod yellow

If we make mistake w ecan edint the pod-definition file and recreate the pod
	terminal --> k replace --force -f yellow.yaml

- click 'Check' button




4. We have deployed an application logging stack in the elastic-stack namespace. Inspect it.
--------------------------------------------------------------------------------------------
Before proceeding with the next set of questions, please wait for all the pods in the elastic-stack namespace to be ready. This can take a few minutes.

List pods in the 'elastic-stack' namespace
	terminal --> k get pods -n elastic-stack

	# result:
	NAME             READY   STATUS    RESTARTS   AGE
	app              1/1     Running   0          27m
	elastic-search   1/1     Running   0          27m
	kibana           1/1     Running   0          27m


- click 'Ok' button





5. Once the pod is in a ready state, inspect the Kibana UI using the link above your terminal. There shouldn't be any logs for now.
------------------------------------------------------------------------------------------------------------------------------

We will configure a sidecar container for the application to send logs to Elastic Search.

NOTE: It can take a couple of minutes for the Kibana UI to be ready after the Kibana pod is ready.

You can inspect the Kibana logs by running:
	terminal --> kubectl -n elastic-stack logs kibana

- click 'Ok' button




6. Inspect the app pod and identify the number of containers in it.
-------------------------------------------------------------------
It is deployed in the elastic-stack namespace.



List pods in elastic-stack namespace
	terminal --> k get pods -n elastic-stack

	# result:
	NAME             READY   STATUS    RESTARTS   AGE
	app              1/1     Running   0          33m
	elastic-search   1/1     Running   0          33m
	kibana           1/1     Running   0          33m


Describe app pod
	terminal --> k describe pod app -n elastic-stack

# result:
----------------------------------------------------
...
Containers:			# only one container
  app:
    Container ID:   containerd://0fe66c0e59d05f3a86715292aa9413a56a59ef61c617551d27a7898921256791
    Image:          kodekloud/event-simulator
    Image ID:       docker.io/kodekloud/event-simulator@sha256:1e3e9c72136bbc76c96dd98f29c04f298c3ae241c7d44e2bf70bcc209b030bf9
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Fri, 07 Mar 2025 10:08:53 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /log from log-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tlcgt (ro)
Conditions:
...
----------------------------------------------------

- choose '1' as answer




7. The application outputs logs to the file /log/app.log. View the logs and try to identify the user having issues with Login.
------------------------------------------------------------------------------------------------------------------------------
Inspect the log file inside the pod.


Show logs of the app pod
	terminal --> k logs app -n elastic-stack

# result:
------------------------------------------
...
[2025-03-07 10:51:32,627] INFO in event-simulator: USER2 logged in
[2025-03-07 10:51:33,632] INFO in event-simulator: USER2 is viewing page3
[2025-03-07 10:51:34,633] INFO in event-simulator: USER3 is viewing page1
[2025-03-07 10:51:35,635] INFO in event-simulator: USER4 is viewing page1
[2025-03-07 10:51:36,636] INFO in event-simulator: USER2 logged out
[2025-03-07 10:51:37,638] WARNING in event-simulator: USER5 Failed to Login as the account is locked due to MANY FAILED ATTEMPTS.
[2025-03-07 10:51:37,638] WARNING in event-simulator: USER7 Order failed as the item is OUT OF STOCK.
...
------------------------------------------
We can see that the USER5 is ahving issues


Or 

Connect to the pod and show logs
	terminal --> k exec -it app -n elastic-stack -- cat /log/app.log

# result:
------------------------------------------
...
[2025-03-07 10:51:32,627] INFO in event-simulator: USER2 logged in
[2025-03-07 10:51:33,632] INFO in event-simulator: USER2 is viewing page3
[2025-03-07 10:51:34,633] INFO in event-simulator: USER3 is viewing page1
[2025-03-07 10:51:35,635] INFO in event-simulator: USER4 is viewing page1
[2025-03-07 10:51:36,636] INFO in event-simulator: USER2 logged out
[2025-03-07 10:51:37,638] WARNING in event-simulator: USER5 Failed to Login as the account is locked due to MANY FAILED ATTEMPTS.
[2025-03-07 10:51:37,638] WARNING in event-simulator: USER7 Order failed as the item is OUT OF STOCK.
...
------------------------------------------
We can see that the USER5 is ahving issues


- choose 'USER5' as answer




8. Edit the pod in the elastic-stack namespace to add a sidecar container to send logs to Elastic Search. Mount the log volume to the sidecar container.
---------------------------------------------------------------------------------------------------------------------------------
Only add a new container. Do not modify anything else. Use the spec provided below.

Note: State persistence concepts are discussed in detail later in this course. For now please make use of the below documentation link for updating the concerning pod.

https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/

Name: app
Container Name: sidecar
Container Image: kodekloud/filebeat-configured
Volume Mount: log-volume
Mount Path: /var/log/event-simulator/
Existing Container Name: app
Existing Container Image: kodekloud/event-simulator


Task approach:
	- We need to add container in the 'app' pod to collect and send data to elastic-stack


List pods in the elastic-stack namespace
	terminal --> k get pods -n elastic-stack

	# result:
	NAME             READY   STATUS    RESTARTS   AGE
	app              1/1     Running   0          4m57s
	elastic-search   1/1     Running   0          4m57s
	kibana           1/1     Running   0          4m56s


Edit the app pod in the elastic-stack namespace
	terminal --> k edit pod app -n elastic-stack

-------------------------------------------
...
  containers:
  - image: kodekloud/filebeat-configured		# added from here
    name: sidecar
    volumeMounts:
    - mountPath: /var/log/event-simulator/
      name: log-volume					# to here
  - image: kodekloud/event-simulator
    imagePullPolicy: Always
...
-------------------------------------------
save changes - escape, :wq!, enter
exit error edit screen - escape, :q!, enter

We receive error:
error: pods "app" is invalid
A copy of your changes has been stored to "/tmp/kubectl-edit-1977662518.yaml"
error: Edit cancelled, no valid changes were saved.


Recreate the app pod in the elastic-stack namespace with the created temporary file
	terminal --> k replace --force -f /tmp/kubectl-edit-1977662518.yaml

	# result:
	pod "app" deleted
	pod/app replaced

- click 'Ã‡heck' button




9.Inspect the Kibana UI. You should now see logs appearing in the Discover section.
-----------------------------------------------------------------------------------
You might have to wait for a couple of minutes for the logs to populate. You might have to create an index pattern to list the logs. If not sure check this video: https://bit.ly/2EXYdHf

Open Kebana tab and go to Management page. We should see 'filebeat-*' header with logs. We can go to Discover page and llok over the logs.


- click 'Ok' button





=============================
Section 4 78. Init Containers
=============================

In a multi-container pod, each container is expected to run a process that stays alive as long as the POD's lifecycle. For example in the multi-container pod that we talked about earlier that has a web application and logging agent, both the containers are expected to stay alive at all times. The process running in the log agent container is expected to stay alive as long as the web application is running. If any of them fails, the POD restarts.


But at times you may want to run a process that runs to completion in a container. For example a process that pulls a code or binary from a repository that will be used by the main web application. That is a task that will be run only one time when the pod is first created. Or a process that waits for an external service or database to be up before the actual application starts. That's where initContainers comes in.


An initContainer is configured in a pod like all other containers, except that it is specified inside a initContainers section, like this:

----------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox
    command: ['sh', '-c', 'git clone <some-repository-that-will-be-used-by-application> ;']
----------------------------------------------


When a POD is first created the initContainer is run, and the process in the initContainer must run to a completion before the real container hosting the application starts.

You can configure multiple such initContainers as well, like how we did for multi-pod containers. In that case each init container is run one at a time in sequential order.

If any of the initContainers fail to complete, Kubernetes restarts the Pod repeatedly until the Init Container succeeds.

----------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! && sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox:1.28
    command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']
  - name: init-mydb
    image: busybox:1.28
    command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;']
----------------------------------------------


Read more about initContainers here. And try out the upcoming practice test.

https://kubernetes.io/docs/concepts/workloads/pods/init-containers/




=============================================
Section 4 80. Practice Test - Init Containers
=============================================


1. Identify the pod that has an initContainer configured.
---------------------------------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME    READY   STATUS    RESTARTS   AGE
	blue    1/1     Running   0          33s
	green   2/2     Running   0          33s	# target pod with 2 containers
	red     1/1     Running   0          33s

How details for all pods
	terminal --> k describe pod

We can see that in the 'blue' pod we have section 'Init Containers:'

- choose 'blue' as answer





2. What is the image used by the initContainer on the blue pod?
---------------------------------------------------------------

Show details for 'blue' container
	terminal --> k describe pod blue

# result:
----------------------------------------
...
Init Containers:
  init-myservice:
    Container ID:  containerd://b6f677988c2702cc083c3d49e07ec69850c49a11f431af49ca338fdb0de47d48
    Image:         busybox		# this is the image of the Init Container
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0
...
----------------------------------------

- choose 'busybox' as answer





3. What is the state of the initContainer on pod blue?
------------------------------------------------------

Show details for 'blue' container
	terminal --> k describe pod blue

# result:
----------------------------------------
...
Init Containers:
  init-myservice:
    Container ID:  containerd://b6f677988c2702cc083c3d49e07ec69850c49a11f431af49ca338fdb0de47d48
    Image:         busybox
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      sleep 5
    State:          Terminated				# this is the state
      Reason:       Completed
      Exit Code:    0
...
----------------------------------------

- choose 'Terminated' as answer





4. Why is the initContainer terminated? What is the reason?
-----------------------------------------------------------

Hint:
Check the Reason field for the initContainer in the kubectl describe pod blue command. This container was terminated after sleeping for 5 seconds.

- choose 'The process completed successfully' as answer





5. We just created a new app named purple. How many initContainers does it have?
--------------------------------------------------------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME     READY   STATUS     RESTARTS   AGE
	blue     1/1     Running    0          13m
	green    2/2     Running    0          13m
	purple   0/1     Init:0/2   0          28s		# we can see 0/2 init containers
	red      1/1     Running    0          13m


Show details for pod purple
	terminal --> k describe pod purple

# result:
-------------------------------------------
Init Containers:
  warm-up-1:										# first init container
    Container ID:  containerd://5f0c478a0d44d9150fd4c38e14eea4deb64650cda8a20fe3e3250b98ceadd2c9
    Image:         busybox:1.28
    Image ID:      docker.io/library/busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      sleep 600
    State:          Running
      Started:      Fri, 07 Mar 2025 11:56:06 +0000
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-92vpt (ro)
  warm-up-2:										# second init container
    Container ID:  
    Image:         busybox:1.28
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      sleep 1200
    State:          Waiting
      Reason:       PodInitializing
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-92vpt (ro)
Containers:
-------------------------------------------

- choose '2' as answer




6. What is the state of the POD?
--------------------------------

List pods
	terminal --> k get pods

	# result:
	NAME     READY   STATUS     RESTARTS   AGE
	blue     1/1     Running    0          15m
	green    2/2     Running    0          15m
	purple   0/1     Init:0/2   0          2m39s
	red      1/1     Running    0          15m


Show details for pod purple
	terminal --> k describe pod purple

# result:
-------------------------------------------
...
Name:             purple
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/192.168.44.58
Start Time:       Fri, 07 Mar 2025 11:56:05 +0000
Labels:           <none>
Annotations:      <none>
Status:           Pending				# this is the state of the pod
IP:               10.22.0.12
IPs:
  IP:  10.22.0.12
Init Containers:
...
-------------------------------------------

- choose 'Pending' as answer





7. How long after the creation of the POD will the application come up and be available to users?
-------------------------------------------------------------------------------------------------


List pods
	terminal --> k get pods

	# result:
	NAME     READY   STATUS     RESTARTS   AGE
	blue     1/1     Running    0          15m
	green    2/2     Running    0          15m
	purple   0/1     Init:0/2   0          2m39s
	red      1/1     Running    0          15m


Show details for pod purple
	terminal --> k describe pod purple

# result:
-------------------------------------------
...
List pods
	terminal --> k get pods

	# result:
	NAME     READY   STATUS     RESTARTS   AGE
	blue     1/1     Running    0          15m
	green    2/2     Running    0          15m
	purple   0/1     Init:0/2   0          2m39s
	red      1/1     Running    0          15m


Show details for pod purple
	terminal --> k describe pod purple

# result:
-------------------------------------------
...
Init Containers:
  warm-up-1:
    Container ID:  containerd://5f0c478a0d44d9150fd4c38e14eea4deb64650cda8a20fe3e3250b98ceadd2c9
    Image:         busybox:1.28
    Image ID:      docker.io/library/busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      sleep 600						# wait 600 - 10 minutes
    State:          Running
      Started:      Fri, 07 Mar 2025 11:56:06 +0000
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-92vpt (ro)
  warm-up-2:
    Container ID:  
    Image:         busybox:1.28
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      sleep 1200					# wait 1200 - 20 minutes
    State:          Waiting
      Reason:       PodInitializing
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-92vpt (ro)
Containers:
...
-------------------------------------------


- choose '30 minutes' as answer







8. Update the pod red to use an initContainer that uses the busybox image and sleeps for 20 seconds
---------------------------------------------------------------------------------------------------
Delete and re-create the pod if necessary. But make sure no other configurations change.

Checks:
	Pod: red
	initContainer Configured Correctly


List pods
	terminal --> k get pods

	# result:
	NAME     READY   STATUS     RESTARTS   AGE
	blue     1/1     Running    0          28m
	green    2/2     Running    0          28m
	purple   0/1     Init:1/2   0          16m
	red      1/1     Running    0          28m		# target pod


Show details for pod red
	terminal --> k describe pod red

	# We can see that no InitContainers are configured

Print the 'red' pod configuration
	terminal --> k get pod red -o yaml

Save the 'red' pod configuration in file red.yaml
	terminal --> k get pod red -o yaml > red.yaml

Edit the configuration of the 'red' container - red.yaml
	terminal --> vi red.yaml

red.yaml
---------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2025-03-07T11:43:30Z"
  name: red
  namespace: default
  resourceVersion: "770"
  uid: 117eda86-9e70-43db-84d3-ba4fbb4cefd7
spec:
 initcontainers:				# added from here
    - image: busybox
      name: red-initcontainer
      command:
        - "sleep"
        - "20"					# to here
  containers:
  - command:
---------------------------------------------
save changes - escape, :wq!, enter

Delete the current 'red' pod
	terminal --> k delete pod red

	# result: pod "red" deleted

Verify the 'red' pod deletion
	terminal --> k get pods

Recreate pod red
	terminal --> k apply -f red.yaml

	# result: pod/red created

Verify the 'red' pod creation
	terminal --> k get pods

- click 'Check' button




9. A new application orange is deployed. There is something wrong with it. Identify and fix the issue.
------------------------------------------------------------------------------------------------------
Once fixed, wait for the application to run before checking solution.


List pods
	terminal --> k get pods

	# result:
	NAME     READY   STATUS                  RESTARTS      AGE
	blue     1/1     Running                 0             43m
	green    2/2     Running                 0             43m
	orange   0/1     Init:CrashLoopBackOff   3 (25s ago)   69s		# target pod
	purple   1/1     Running                 0             31m
	red      1/1     Running                 0             110s


Show details for the pod
	terminal --> k describe pod orange


In section 'Events' we can see log message:
--------------------------------------------------------------------------------------
  Warning  BackOff    4s (x10 over 109s)  kubelet            Back-off restarting failed container init-myservice in pod orange_default(e1358c80-1f91-4c05-86ac-a98b0f6bc083)
--------------------------------------------------------------------------------------

In section 'InitContainers' we can see wrong command
-----------------------------------------------
...
Init Containers:
  init-myservice:
    Container ID:  containerd://0509dcf9a0d3b08d1ca59aec1fb342ee135fb33e562b5154e21df97f15d1e8cc
    Image:         busybox
    Image ID:      docker.io/library/busybox@sha256:498a000f370d8c37927118ed80afe8adc38d1edcbfc071627d17b25c88efcab0
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      sleeeep 2;			# wrong command
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
...
-----------------------------------------------


Edit the pod and ix te command in the 'InitContainers' section
	terminal --> k edit pod orange

# result:
------------------------------------
...
  initContainers:
  - command:
    - sh
    - -c
    - sleep 2;
...
------------------------------------
save changes - escape, :wq!, enter
exit the edit error screen - escape, :q!, enter

We receive error message:
error: pods "orange" is invalid
A copy of your changes has been stored to "/tmp/kubectl-edit-1787255900.yaml"
error: Edit cancelled, no valid changes were saved.


Recreate the 'orange' pod with the created temporary file
	terminal --> k replace --force -f /tmp/kubectl-edit-1787255900.yaml

	# result:
	pod "orange" deleted
	pod/orange replaced

- click 'Check' button















